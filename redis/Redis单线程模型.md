# Redis单线程模型

Redis 基于 **Reactor 模式**开发了自己的网络事件处理器：这个处理器被称为文件事件处理器（file event handler）。文件事件处理器使用 I/O 多路复用（multiplexing）程序来同时监听多个套接字，并根据套接字目前执行的任务来为套接字关联不同的事件处理器。

当被监听的套接字准备好执行连接应答（accept）、读取（read）、写入（write）、关 闭（close）等操作时，与操作相对应的文件事件就会产生，这时文件事件处理器就会调用套接字之前关联好的事件处理器来处理这些事件。

**虽然文件事件处理器以单线程方式运行，但通过使用 I/O 多路复用程序来监听多个套接字**，文件事件处理器既实现了高性能的网络通信模型，又可以很好地与 Redis 服务器中其他同样以单线程方式运行的模块进行对接，这保持了 Redis 内部单线程设计的简单性。

> I/O多路复用：一个进程维护多个Socket



## Redis没有使用多线程？为什么不用多线程？

1. 使用单线程模型能带来更好的可维护性，方便开发和调试；
2. 使用单线程模型也能并发的处理客户端的请求；
   - 使用 I/O 多路复用机制**并发**处理来自客户端的多个连接
3. **Redis 服务中运行的绝大多数操作的性能瓶颈都不是 CPU，而是在内存和网络**
   - 多线程技术能够帮助我们充分利用CPU资源来并发执行不同的任务，但CPU往往不是Redis的性能瓶颈
   - using pipelining Redis running on an average Linux system can deliver even 1 million requests per second, so if your application mainly **uses O(N) or O(log(N)) commands**, it is hardly going to use too much CPU.
   - 如果这种吞吐量不能满足要求的话，最好的做法就是上集群+分片，将不同请求交给不同Redis服务器来处理

**Redis6.0引入了多线程**

- 主要为了提高网络IO读写能力，因为这个算是 Redis 中的一个性能瓶颈（Redis 的瓶颈主要受限于内存和网络）。

  - 多线程默认是禁用的

  - 开启多线程后，还需要设置线程数，否则是不生效的。

  - ```bash
    io-threads-do-reads yes
    io-threads 4 #官网建议4核的机器建议设置为2或3个线程，8核的建议设置为6个线程
    ```

- 对于大键的删除，Redis可能会需要在释放内存空间上消耗更多时间，这就会阻塞待处理的任务，然而释放内存空间可以在后台异步处理，引入多线程的另一目的就是对一个大键值对的删除



## 文件事件处理器的四个部分

- 多个socket（客户端连接）
- I/O多路复用程序（支持多个客户端连接的关键）
- 文件事件分派器（将socket关联到相应的事件处理器）
- 事件处理器（连接应答处理器、命令请求处理器、命令回复处理器）
- 连接多个套接字，文件事件可能并发出现，但I/O多路复用程序会将套接字放在一个队列里面有序、同步、每次一个套接字的方式向文件事件分派器传送套接字。

![image-20220225093051308](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225093051308.png)



## I/O 多路复用：select/poll/epoll

### 最基本的 Socket 模型

客户端和服务器能在网络中通信，那必须得使⽤ Socket 编程，它是进程间通信⾥⽐较特别的⽅式，特别之处在于它是可以跨主机间通信。

1、创建 Socket 的时候，可以指定⽹络层使⽤的是 IPv4 还是 IPv6，传输层使⽤的是 TCP 还是 UDP。（这里看TCP的）

2、服务端⾸先调⽤ **socket()** 函数，创建⽹络协议为 IPv4，以及传输协议为 TCP 的 Socket ，接着调⽤**bind()** 函数，给这个 Socket 绑定⼀个 IP 地址和端⼝（绑的是自己的IP和监听的端口）

- 绑定端口的目的：当内核收到 TCP 报⽂，通过 TCP 头⾥⾯的端⼝号，若有socket监听这个端口，就接收
- 绑定 IP 地址的⽬的：⼀台机器是可以有多个⽹卡的，每个⽹卡都有对应的 IP 地址，当绑定⼀个⽹卡时，内核在收到该⽹卡上的包，才会发给我们；

3、绑定完 IP 地址和端⼝后，就可以调⽤ **listen()** 函数进⾏监听，此时对应 TCP 状态图中的 listen，如果我们要判定服务器中⼀个⽹络程序有没有启动，可以通过 netstat 命令查看对应的端⼝号是否有被监听。

- `netstat -anp | grep 3306`

4、服务端进⼊了监听状态后，通过调⽤ **accept()** 函数，来从内核获取客户端的连接，如果没有客户端连接，则会阻塞等待客户端连接的到来。

5、客户端如何发起连接的？客户端在创建好 Socket 后，调⽤ connect() 函数发起连接，该函数的参数要指明服务端的 IP 地址和端⼝号，然后的 TCP 三次握⼿就开始了。

> 在TCP的三次连接中，Linux内核会为每个socket维护两个队列
>
> - 半连接队列：还没完成建立连接的队列，都没有完成三次握手，这个队列中，服务端发送了ACK+SYN，处于syn-rcvd的状态
> - 全连接队列：已经建立连接，完成了三次握手，服务端处于estblished的状态

6、当TCP全连接队列不为空后，服务端的**accept()**函数，就会从内核中的TCP全连接队列拿出一个已经完成连接的Socket返回给应用程序，后续传输都用这个Socket

> 监听的 Socket 和真正⽤来传数据的 Socket 是两个：
>
> - 一个是监听Socket
> - 一个是已连接Socket

7、连接建⽴后，客户端和服务端就开始相互传输数据了，双⽅都可以通过 read() 和 write() 函数来读写数据

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225100841399.png" alt="image-20220225100841399" style="zoom:50%;" />



### 如何服务更多的用户？

前⾯提到的 TCP Socket 调⽤流程是最简单、最基本的，它基本只能⼀对⼀通信，因为使⽤的是同步阻塞的⽅式，当服务端在还没处理完⼀个客户端的⽹络 I/O 时，或者 读写操作发⽣阻塞时，其他客户端是⽆法与服务端连接的。

> C10K,单机同时处理1万并发



### 多进程模型

基于最原始的阻塞⽹络 I/O， 如果服务器要⽀持多个客户端，其中⽐较传统的⽅式，就是使⽤多进程模型，也就是为每个客户端分配⼀个进程来处理请求。

服务器的主进程负责监听客户的连接，⼀旦与客户端连接完成，accept() 函数就会返回⼀个「已连接Socket」，这时就通过 fork() 函数创建⼀个⼦进程，实际上就把⽗进程所有相关的东⻄都复制⼀份，包括⽂件描述符、内存地址空间、程序计数器、执⾏的代码等。

这两个进程刚复制完的时候，⼏乎⼀摸⼀样。不过，会根据返回值来区分是⽗进程还是⼦进程，如果返回值是 0，则是⼦进程；如果返回值是其他的整数，就是⽗进程。

正因为⼦进程会复制⽗进程的⽂件描述符，于是就可以直接使⽤「已连接 Socket 」和客户端通信了，

可以发现，⼦进程不需要关⼼「监听 Socket」，只需要关⼼「已连接 Socket」；⽗进程则相反，将客户
服务交给⼦进程来处理，因此⽗进程不需要关⼼「已连接 Socket」，只需要关⼼「监听 Socket」。

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225102345633.png" alt="image-20220225102345633" style="zoom:80%;" />

这种⽤多个进程来应付多个客户端的⽅式，在应对 100 个客户端还是可⾏的，但是当客户端数量⾼达⼀万时，肯定扛不住的，因为每产⽣⼀个进程，必会占据⼀定的系统资源，⽽且进程间上下⽂切换的“包袱”是很重的，性能会⼤打折扣。
进程的上下⽂切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。



### 多线程模型

如果每来⼀个连接就创建⼀个线程，线程运⾏完后，还得操作系统还得销毁线程，虽说线程切换的上写⽂开销不⼤，但是如果频繁创建和销毁线程，系统开销也是不⼩的。

那么，我们可以使⽤**线程池的⽅式**来避免线程的频繁创建和销毁，所谓的线程池，就是提前创建若⼲个线程，这样当由新连接建⽴时，将这个已连接的 Socket 放⼊到⼀个队列⾥，然后线程池⾥的线程负责从队列中取出已连接 Socket 进程处理。

![image-20220225102658523](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225102658523.png)

需要注意的是，这个队列是全局的，每个线程都会操作，为了避免多线程竞争，线程在操作这个队列前要加锁。（生产者消费者模式）



### I/O多路复用

select/poll/epoll 内核提供给⽤户态的多路复⽤系统调⽤，进程可以**通过⼀个系统调⽤函数从内核中获取多个事件**。

> I/O多路复用：一个进程维护多个Socket
>
> 文件描述符fd是内核为了高效管理已被打开的文件所创建的索引，用于指代被打开的文件，对文件所有IO操作相关的系统调用都通过它。linux一切皆文件。

#### select/poll

select实现I/O多路复用的方式，将已连接的Socket放到一个**文件描述符集合**（数组，有上限,默认是1024），然后调用select函数将文件描述符集合拷贝到内核里，让内核来检查是否有网络事件的发生，检查的方式就是**遍历（轮询）**文件描述符集合，当检查到有事件产生后，将此Socket**标记为可读可写**，接着再把整个文件描述符拷贝回用户态，然后用户态还需要通过遍历的方式找到可读可写的Socket，再对其处理。

**select的方式，需要两个遍历文件描述符集合，一次是在内核态，一次是在用户态，还会发生两次拷贝文件描述符，先从用户态传入内核态，经过内核态修改后，再传回用户态。**

select 使⽤固定⻓度的 BitsMap，表示⽂件描述符集合，⽽且所⽀持的⽂件描述符的个数是有限制的，在Linux 系统中，由内核中的 FD_SETSIZE 限制， 默认最⼤值为 1024 ，只能监听 0~1023 的⽂件描述符

poll 不再⽤ BitsMap 来存储所关注的⽂件描述符，取⽽代之⽤动态数组，以链表形式来组织，突破了select 的⽂件描述符个数限制，当然还会受到系统⽂件描述符限制。

但是 **poll 和 select 并没有太⼤的本质区别**，都是**使⽤「线性结构」存储进程关注的 Socket 集合**，因此都需要遍历⽂件描述符集合来找到可读或可写的 Socket，时间复杂度为 O(n)，⽽且也需要在⽤户态与内核态之间拷⻉⽂件描述符集合，这种⽅式随着并发数上来，性能的损耗会呈指数级增⻓。

#### epoll

epoll 通过两个⽅⾯，很好解决了 select/poll 的问题。

一、epoll在**内核中用红黑树**来跟踪进程所有待检测的文件描述符，把需要监控的Socket通过`epoll_ctl()`函数加入到内核中的红黑树里，红黑树是一个高级的数据结构，增删改都是`O(logn)`,通过对这棵树操作，就不需要像select/poll那样每次传入整个Socket集合，只需要传入一个待检测的socket，减少了内核和用户空间来回拷贝

二、**epoll使用事件驱动的机制**，内核里维护了一个链表来记录就绪事件，当某个socket有事件发生，通过回调函数(callback)，内核会将其加入到就绪事件列表，当用户调用`epoll_wait()`，只会返回有事件发生的文件描述符，不需要像select/poll那样轮询整个socket集合

> epoll_wait 实现的内核代码中调⽤了 __put_user 函数，这个函数就是将数据从内核拷⻉到⽤户空间。

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225104026751.png" alt="image-20220225104026751" style="zoom:80%;" />

#### ET和LT

epoll支持两种事件触发模式，分别是**边缘触发（Edge-triggered,ET）和水平触发（level-triggered,LT）**

- 使用边缘触发的时候，当被监控的Socket描述符上有可读事件时，服务器只会从`epoll_wait`中苏醒一次，即使进程没有调用read函数从内核读取数据，也依然只会苏醒一次，因此要保证程序一次性将内核缓冲区的数据读取完。
- 使用水平触发的时候，当被监控的Socket有可读事件，服务器端不断地从`epoll_wait`中苏醒，直到内核缓冲区数据被read函数读完才结束，目的是告诉我们有数据需要读取。

举个例⼦，你的快递被放到了⼀个快递箱⾥，如果快递员只会通过短信通知你⼀次，即使你⼀直没有去取，它也不会再发送第⼆条短信提醒你，这个⽅式就是边缘触发；如果快递员发现你的快递没有被取出，它就会不停地发短信通知你，直到你取出了快递，它才消停，这个就是⽔平触发的⽅式。

**⽔平触发的意思是只要满⾜事件的条件，⽐如内核中有数据需要读，就⼀直不断地把这个事件传递给⽤户；⽽边缘触发的意思是只有第⼀次满⾜条件的时候才触发，之后就不会再传递同样的事件了。**

如果使⽤⽔平触发模式，当内核通知⽂件描述符可读写时，接下来还可以继续去检测它的状态，看它是否依然可读或可写。所以在收到通知后，没必要⼀次执⾏尽可能多的读写操作。

如果使⽤边缘触发模式，I/O 事件发⽣时只会通知⼀次，⽽且我们不知道到底能读写多少数据，所以在收到通知后应尽可能地读写数据，以免错失读写的机会。因此，我们会循环从⽂件描述符读写数据，那么如果⽂件描述符是阻塞的，没有数据可读写时，进程会阻塞在读写函数那⾥，程序就没办法继续往下执⾏。所以，边缘触发模式⼀般和⾮阻塞 I/O 搭配使⽤，程序会⼀直执⾏ I/O 操作，直到系统调⽤（如 read 和write ）返回错误，错误类型为 **EAGAIN 或 EWOULDBLOCK** 。

⼀般来说，边缘触发的效率⽐⽔平触发的效率要⾼，因为边缘触发可以减少 epoll_wait 的系统调⽤次数，系统调⽤也是有⼀定的开销的的，毕竟也存在上下⽂的切换。

**select/poll 只有⽔平触发模式，epoll 默认的触发模式是⽔平触发，但是可以根据应⽤场景设置为边缘触发模式。**

另外，使⽤ I/O 多路复⽤时，最好搭配⾮阻塞 I/O ⼀起使⽤，多路复⽤ API 返回的事件并不⼀定可读写的，如果使⽤阻塞 I/O， 那么在调⽤read/write 时则会发⽣程序阻塞，因此最好搭配⾮阻塞 I/O，以便应对极少数的特殊情况。

> 系统调用：是用户程序和操作系统之间的接口
>
> ⽤户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间。因此，当程序使⽤⽤户空间时，我们常说该程序在⽤户态执⾏，⽽当程序使内核空间时，程序则在内核态执⾏。
>
> 一旦一个应用程序执行系统调用成功，其 CPU 运行状态将发生变化，由用户层的 Ring3 转移至内核层的 Ring 0
>
> - 内核层次的代码为特权指令，只能在 CPU 的 Ring 0 状态下运行
>
> 应⽤程序如果需要进⼊内核空间，就需要通过系统调⽤，下⾯来看看系统调⽤的过程：
>
> <img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225105504414.png" alt="image-20220225105504414" style="zoom:50%;" />
>
> 内核程序执⾏在内核态，⽤户程序执⾏在⽤户态。当应⽤程序使⽤系统调⽤时，会产⽣⼀个中断。发⽣中断后， CPU 会中断当前在执⾏的⽤户程序，转⽽跳转到中断处理程序，也就是开始执⾏内核程序。内核处理完后，主动触发中断，把 CPU 执⾏权限交回给⽤户程序，回到⽤户态继续⼯作。



## 阻塞与非阻塞 I/O VS 同步与异步 I/O

![image-20220225101814497](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225101814497.png)

I/O是分为两个过程的：

1、数据准备过程

2、数据从内核缓冲区拷贝回用户进程缓冲区的过程

阻塞I/O会阻塞在【过程1】和【过程2】，而非阻塞I/O和基于非阻塞I/O的多路复用会阻塞在【过程2】，所以这三个是同步I/O

异步I/O这两个过程都不会阻塞



### 阻塞I/O

阻塞I/O，当应用程序执行`read`,线程会被阻塞，一直等待内核数据准备好，并把数据从内核缓冲区拷贝回应用程序的缓冲区，当拷贝完成，`read`才结束

**阻塞等待的是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程**

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225101208694.png" alt="image-20220225101208694" style="zoom:67%;" />

### 非阻塞I/O

非阻塞的`read`请求会在数据未准备好的情况下立即返回，可以继续往下执行，此时应用程序不断轮询内核，直到数据准备好，内核将数据拷贝到应用程序缓冲区,`read`才算完成

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225101335242.png" alt="image-20220225101335242" style="zoom: 67%;" />

**这⾥最后⼀次 read 调⽤，获取数据的过程，是⼀个同步的过程，是需要等待的过程。这里的同步指的是内核态的数据拷⻉到⽤户程序的缓存区这个过程。**

为了解决这种傻乎乎轮询⽅式，于是 I/O 多路复⽤技术就出来了，如 **select、poll，它是通过 I/O 事件分发**，当内核数据准备好时，再以事件通知应⽤程序进⾏操作。这个做法⼤⼤改善了应⽤进程对 CPU 的利⽤率，在没有被通知的情况下，应⽤进程可以使⽤ CPU 做其他
的事情。

下图是使⽤ select I/O 多路复⽤过程。注意， read 获取数据的过程（数据从内核态拷⻉到⽤户态的过程），也是⼀个**同步的过程**，需要等待：

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225101547252.png" alt="image-20220225101547252" style="zoom:67%;" />

### 同步I/O

实际上，⽆论是**阻塞 I/O、⾮阻塞 I/O，还是基于⾮阻塞 I/O 的多路复⽤都是同步调⽤**。因为它们在 read调⽤时，内核将数据从内核空间拷⻉到应⽤程序空间，过程都是需要等待的，也就是说这个过程是同步的，如果内核实现的拷⻉效率不⾼，read 调⽤就会在这个同步过程中等待⽐较⻓的时间。

**真正的异步 I/O 是「内核数据准备好」和「数据从内核态拷⻉到⽤户态」这两个过程都不⽤等待。**

### 异步I/O

当我们发起 aio_read 之后，就⽴即返回，内核⾃动将数据从内核空间拷⻉到应⽤程序空间，这个拷⻉过程同样是异步的，内核⾃动完成的，和前⾯的同步操作不⼀样，应⽤程序并不需要主动发起拷⻉动作

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225101746649.png" alt="image-20220225101746649" style="zoom:67%;" />



## Reator

Reactor模式：基于⾯向对象的思想，对 I/O 多路复⽤作了⼀层封装，让使⽤者不⽤考虑底层⽹络 API 的细节，只需要关注应⽤代码的编写。

Reactor 模式也叫 Dispatcher 模式，即 I/O 多路复⽤监听事件，收到事件后，根据事件类型分配（Dispatch）给某个进程 / 线程。

Reactor 模式主要由 Reactor 和处理资源池这两个核⼼部分组成，它俩负责的事情如下：

- Reactor 负责监听和分发事件，事件类型包含连接事件、读写事件；
- 处理资源池负责处理事件，如 read -> 业务逻辑 -> send；

⼀般来说，C 语⾔实现的是「单 Reactor 单进程 」的⽅案，因为 C 语编写完的程序，运⾏后就是⼀个独⽴的进程，不需要在进程中再创建线程。**Redis就是单Reactor单进程的方案**

⽽ Java 语⾔实现的是「单 Reactor 单线程 」的⽅案，因为 Java 程序是跑在 Java 虚拟机这个进程上⾯的，虚拟机中有很多线程，我们写的 Java 程序只是其中的⼀个线程⽽已。

### 单 Reactor 单进程

「单 Reactor 单进程」的⽅案示意图

![image-20220225112443538](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225112443538.png)

可以看到进程⾥有 Reactor、Acceptor、Handler 这三个对象：

- Reactor 对象的作⽤是监听和分发事件；(Redis中的I/O多路复用组件和文件事件分派器)
- Acceptor 对象的作⽤是获取连接；（连接应答处理器）
- Handler 对象的作⽤是处理业务；（命令回复处理器，命令请求处理器等...）

对象⾥的 select、accept、read、send 是系统调⽤函数，dispatch 和 「业务处理」是需要完成的操作，其中 dispatch 是分发事件操作。

接下来，介绍下「单 Reactor 单进程」这个⽅案：

- Reactor 对象通过 select （IO 多路复⽤接⼝） 监听事件，收到事件后通过 dispatch 进⾏分发，具体分发给 Acceptor 对象还是 Handler 对象，还要看收到的事件类型；
- 如果是连接建⽴的事件，则交由 Acceptor 对象进⾏处理，Acceptor 对象会通过 accept ⽅法 获取连接，并创建⼀个 Handler 对象来处理后续的响应事件；
- 如果不是连接建⽴事件， 则交由当前连接对应的 Handler 对象来进⾏响应；
- Handler 对象通过 read -> 业务处理 -> send 的流程来完成完整的业务流程。

优点：

- 单 Reactor 单进程的⽅案因为全部⼯作都在同⼀个进程内完成，所以实现起来⽐较简单，不需要考虑进程间通信，也不⽤担⼼多进程竞争

缺点：

- 因为只有⼀个进程，⽆法充分利⽤ 多核 CPU 的性能；
- Handler 对象在业务处理时，整个进程是⽆法处理其他连接的事件的，如果业务处理耗时⽐较⻓，那么就造成响应的延迟；

所以，**单 Reactor 单进程的⽅案不适⽤I/O密集型的场景，只适⽤于业务处理⾮常快速的场景。**

**Redis 是由 C 语⾔实现的，它采⽤的正是「单 Reactor 单进程」的⽅案，因为 Redis 业务处理主要是在内存中完成，操作的速度是很快的，性能瓶颈不在 CPU 上，所以 Redis 对于命令的处理是单进程的⽅案。**