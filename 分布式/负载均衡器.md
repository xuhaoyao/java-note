# 负载均衡

集群中的应用服务器（节点）通常被设计成无状态，用户可以请求任何一个节点。

负载均衡器会根据集群中每个节点的负载情况，将用户请求转发到合适的节点上。

负载均衡器可以用来实现高可用以及伸缩性：

- 高可用：当某个节点故障时，负载均衡器会将用户请求转发到另外的节点上，从而保证所有服务持续可用；
- 伸缩性：根据系统整体负载情况，可以很容易地添加或移除节点。

负载均衡器运行过程包含两个部分：

1. 根据负载均衡算法得到转发的节点；
2. 将请求进行转发。

## 负载均衡算法

#### 1. 轮询（Round Robin）

轮询算法把每个请求轮流发送到每个服务器上。

下图中，一共有 6 个客户端产生了 6 个请求，这 6 个请求按 (1, 2, 3, 4, 5, 6) 的顺序发送。(1, 3, 5) 的请求会被发送到服务器 1，(2, 4, 6) 的请求会被发送到服务器 2。

![image-20220808225018447](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808225018447.png)

该算法比较适合每个服务器的性能差不多的场景，如果有性能存在差异的情况下，那么性能较差的服务器可能无法承担过大的负载（下图的 Server 2）。

![image-20220808225032605](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808225032605.png)

#### 2. 加权轮询（Weighted Round Robbin）

加权轮询是在轮询的基础上，根据服务器的性能差异，为服务器赋予一定的权值，性能高的服务器分配更高的权值。

例如下图中，服务器 1 被赋予的权值为 5，服务器 2 被赋予的权值为 1，那么 (1, 2, 3, 4, 5) 请求会被发送到服务器 1，(6) 请求会被发送到服务器 2。

![image-20220808225052869](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808225052869.png)

#### 3. 最少连接（least Connections）

由于每个请求的连接时间不一样，使用轮询或者加权轮询算法的话，可能会让一台服务器当前连接数过大，而另一台服务器的连接过小，造成负载不均衡。

例如下图中，(1, 3, 5) 请求会被发送到服务器 1，但是 (1, 3) 很快就断开连接，此时只有 (5) 请求连接服务器 1；(2, 4, 6) 请求被发送到服务器 2，只有 (2) 的连接断开，此时 (6, 4) 请求连接服务器 2。该系统继续运行时，服务器 2 会承担过大的负载。

![image-20220808225114527](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808225114527.png)

最少连接算法就是将请求发送给当前最少连接数的服务器上。

例如下图中，服务器 1 当前连接数最小，那么新到来的请求 6 就会被发送到服务器 1 上。

![image-20220808225151058](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808225151058.png)

#### 4. 加权最少连接（Weighted Least Connection）

在最少连接的基础上，根据服务器的性能为每台服务器分配权重，再根据权重计算出每台服务器能处理的连接数。

#### 5. 随机算法（Random）

把请求随机发送到服务器上。

和轮询算法类似，该算法比较适合服务器性能差不多的场景。

#### 6. 源地址哈希法 (IP Hash)

源地址哈希通过对客户端 IP 计算哈希值之后，再对服务器数量取模得到目标服务器的序号。

可以保证同一 IP 的客户端的请求会转发到同一台服务器上，用来实现会话粘滞（Sticky Session）

![image-20220808225238147](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808225238147.png)

#### 7.一致性Hash算法

源地址哈希算法有一个很严重的问题，当服务器增加或者减少的时候，原来的哈希路由几乎全都被打乱了，实现会话粘滞还好，用户只需要重新登录，若是缓存呢？缓存几乎全部失效，访问压力全给到数据库，这将大大超过数据库的负载能力，严重的可能会导致数据库宕机（缓存雪崩）。

一致性Hash算法通过一个叫作一致性Hash环的数据结构实现KEY到服务器的Hash映射，如图6.11所示。

![image-20220808230427792](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808230427792.png)

具体算法过程为：先构造一个长度为0~2^32的整数环（这个环被称作一致性Hash环），根据节点名称的Hash值（其分布范围同样为0~2^32）将缓存服务器节点放置在这个Hash环上。然后根据需要缓存的数据的KEY值计算得到其Hash值（其分布范围也同样为0~2^32），然后在Hash环上顺时针查找距离这个KEY的Hash值最近的缓存服务器节点，完成KEY到服务器的Hash映射查找。

在图6.11中，假设NODE1的Hash值为3,594,963,423，NODE2的Hash值为1,845,328,979，而KEY0的Hash值为2,534,256,785，那么KEY0在环上顺时针查找，找到的最近的节点就是NODE1。当缓存服务器集群需要扩容的时候，只需要将新加入的节点名称（NODE3）的Hash值放入一致性Hash环中，由于KEY是顺时针查找距离其最近的节点，因此新加入的节点只影响整个环中的一小段，如图6.12中深色一段。

![image-20220808230612497](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808230612497.png)

**具体应用中，这个长度为2^32的一致性Hash环通常使用二叉查找树实现，Hash查找过程实际上是在二叉查找树中查找不小于查找数的最小数值。当然这个二叉树的最右边叶子节点和最左边的叶子节点相连接，构成环。**

但是，上面描述的算法过程还存在一个小小的问题。新加入的节点NODE3只影响了原来的节点NODE1，也就是说一部分原来需要访问NODE1的数据现在需要访问NODE3（概率上是50%）。但是原来的节点NODE0和NODE2不受影响，这就意味着NODE0和NODE2数据量和负载压力是NODE1与NODE3的两倍。如果4台机器的性能是一样的，那么这种结果显然不是我们需要的。

**怎么办？**

**计算机领域有句话：计算机的任何问题都可以通过增加一个虚拟层来解决。**计算机硬件、计算机网络、计算机软件都莫不如此。计算机网络的7层协议，每一层都可以看作是下一层的虚拟层；计算机操作系统可以看作是计算机硬件的虚拟层；Java虚拟机可以看作是操作系统的虚拟层；分层的计算机软件架构事实上也是利用虚拟层的概念。

解决上述一致性Hash算法带来的负载不均衡问题，也可以通过使用虚拟层的手段：将每台物理服务器虚拟为一组虚拟服务器，将虚拟服务器的Hash值放置在Hash环上，KEY在环上先找到虚拟服务器节点，再得到物理服务器的信息。这样新加入物理服务器节点时，是将一组虚拟节点加入环中，如果虚拟节点的数目足够多，这组虚拟节点将会影响同样多数目的已经在环上存在的虚拟节点，这些已经存在的虚拟节点又对应不同的物理节点。最终的结果是：新加入一台服务器，将会较为均匀地影响原来集群中已经存在的所有服务器，也就是说分摊原有服务器集群中所有服务器的一小部分负载, 如图6.13所示。

![image-20220808230923521](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808230923521.png)



## 请求转发技术

如果HTTP请求分发装置可以感知或者可以配置集群的服务器数量，可以及时发现集群中新上线或下线的服务器，并能向新上线的服务器分发请求，停止向已下线的服务器分发请求，那么就实现了应用服务器集群的伸缩性。

这里，这个HTTP请求分发装置被称作负载均衡服务器。

负载均衡是网站必不可少的基础技术手段，不但可以实现网站的伸缩性，同时还改善网站的可用性，可谓网站的杀手锏之一。具体的技术实现也多种多样，从硬件实现到软件实现，从商业产品到开源软件，应有尽有，但是实现负载均衡的基础技术不外以下几种。

### HTTP重定向负载均衡

利用HTTP重定向协议实现负载均衡。如图6.5所示。

![image-20220808231423392](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808231423392.png)

HTTP重定向服务器是一台普通的应用服务器，其唯一的功能就是根据用户的HTTP请求计算一台真实的Web服务器地址，并将该Web服务器地址写入HTTP重定向响应中（响应状态码302）返回给用户浏览器。

这种负载均衡方案的优点是比较简单。缺点是浏览器需要两次请求服务器才能完成一次访问，性能较差；重定向服务器自身的处理能力有可能成为瓶颈，整个集群的伸缩性规模有限；使用HTTP302响应码重定向，有可能使搜索引擎判断为SEO作弊，降低搜索排名。因此实践中使用这种方案进行负载均衡的案例并不多见。

### DNS域名解析负载均衡

这是利用DNS处理域名解析请求的**同时进行负载均衡处理**的一种方案，如图6.6所示。

![image-20220808232215604](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808232215604.png)

在DNS服务器中配置多个A记录，如：

www.mysite.com IN A 114.100.80.1

www.mysite.com IN A 114.100.80.2

www.mysite.com IN A 114.100.80.3。

每次域名解析请求都会根据负载均衡算法计算一个不同的IP地址返回，这样A记录中配置的多个服务器就构成一个集群，并可以实现负载均衡。图6.6中的浏览器请求解析域名www.mysite.com，DNS根据A记录和负载均衡算法计算得到一个IP地址114.100.80.3，并返回给浏览器；浏览器根据该IP地址，访问真实物理服务器114.100.80.3。

DNS域名解析负载均衡的优点是将负载均衡的工作转交给DNS，省掉了网站管理维护负载均衡服务器的麻烦，同时许多DNS还支持基于地理位置的域名解析，即会将域名解析成距离用户地理最近的一个服务器地址，这样可加快用户访问速度，改善性能。

但是DNS域名解析负载均衡也有缺点，就是目前的DNS是多级解析，每一级DNS都可能缓存A记录，当下线某台服务器后，即使修改了DNS的A记录，要使其生效也需要较长时间，这段时间，DNS依然会将域名解析到已经下线的服务器，导致用户访问失败；而且DNS负载均衡的控制权在域名服务商那里，网站无法对其做更多改善和更强大的管理。

事实上，大型网站总是部分使用DNS域名解析，利用域名解析作为第一级负载均衡手段，即域名解析得到的一组服务器并不是实际提供Web服务的物理服务器，而是同样提供负载均衡服务的内部服务器，这组内部负载均衡服务器再进行负载均衡，将请求分发到真实的Web服务器上。

### 反向代理负载均衡

利用反向代理服务器进行负载均衡，如图6.7所示。

![image-20220808232543903](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808232543903.png)

可以利用反向代理缓存资源，以改善网站性能。实际上，在部署位置上，反向代理服务器处于Web服务器前面（这样才可能缓存Web响应，加速访问），这个位置也正好是负载均衡服务器的位置，所以大多数反向代理服务器同时提供负载均衡的功能，管理一组Web服务器，将请求根据负载均衡算法转发到不同Web服务器上。Web服务器处理完成的响应也需要通过反向代理服务器返回给用户。由于Web服务器不直接对外提供访问，因此Web服务器不需要使用外部I P地址，而反向代理服务器则需要配置双网卡和内部外部两套IP地址。

由于反向代理服务器转发请求在HTTP协议层面，因此也叫应用层负载均衡。其优点是和反向代理服务器功能集成在一起，部署简单。缺点是反向代理服务器是所有请求和响应的中转站，其性能可能会成为瓶颈。

### IP负载均衡

在网络层通过修改请求目标地址进行负载均衡，如图6.8所示。

![image-20220808232723013](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808232723013.png)

用户请求数据包到达负载均衡服务器114.100.80.10后，负载均衡服务器在操作系统内核进程获取网络数据包，根据负载均衡算法计算得到一台真实Web服务器10.0.0.1，然后将数据目的IP地址修改为10.0.0.1，不需要通过用户进程处理。真实Web应用服务器处理完成后，响应数据包回到负载均衡服务器，**负载均衡服务器再将数据包源地址修改为自身的IP地址（114.100.80.10）发送给用户浏览器**。

> 负载均衡服务器在修改目的IP地址的同时修改源地址，将数据包源地址设为自身IP，即源地址转换（SNAT），这样Web服务器的响应会再回到负载均衡服务器

**IP负载均衡在内核进程完成数据分发**，较反向代理负载均衡（在应用程序中分发数据）有更好的处理性能。但是由于所有请求响应都需要经过负载均衡服务器，集群的最大响应数据吞吐量不得不受制于负载均衡服务器网卡带宽。对于提供下载服务或者视频服务等需要传输大量数据的网站而言，难以满足需求。**能不能让负载均衡服务器只分发请求，而使响应数据从真实物理服务器直接返回给用户呢？**

### 数据链路层负载均衡

顾名思义，数据链路层负载均衡是指在通信协议的数据链路层修改mac地址进行负载均衡，如图6.9所示。

![image-20220808233115598](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220808233115598.png)

**这种数据传输方式又称作三角传输模式**，负载均衡数据分发过程中**不修改IP地址，只修改目的mac地址**，**通过配置真实物理服务器集群所有机器虚拟IP和负载均衡服务器IP地址一致**，从而达到不修改数据包的源地址和目的地址就可以进行数据分发的目的，由于实际处理请求的真实物理服务器IP和数据请求目的IP一致，不需要通过负载均衡服务器进行地址转换，可将响应数据包直接返回给用户浏览器，避免负载均衡服务器网卡带宽成为瓶颈。**这种负载均衡方式又称作直接路由方式（DR）。**

使用三角传输模式的链路层负载均衡是目前大型网站使用最广的一种负载均衡手段。在Linux平台上最好的链路层负载均衡开源产品是LVS（Linux Virtual Server）。