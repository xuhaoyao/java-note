# 操作系统

## 什么是操作系统？

1、操作系统本质上是一个运行在计算机的软件程序，用来**管理计算机硬件和软件资源**。运行在电脑上的所有应用程序都需要通过操作系统来调用系统内存和磁盘等等硬件资源

2、操作系统的存在屏蔽了硬件层的复杂性，操作系统内核会负责系统的内存管理，硬件设备管理，文件系统管理，内核是连接应用程序和硬件的桥梁，决定着系统的性能和稳定性。

3、系统调用是用户程序和操作系统之间的接口

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225125551726.png" alt="image-20220225125551726" style="zoom:50%;" />



## 什么是系统调用？

内核具有很⾼的权限，可以控制 cpu、内存、硬盘等硬件，⽽应⽤程序具有的权限很⼩，因此⼤多数操作系统，把内存分成了两个区域：

用户态：用户态运行的进程可以直接读取用户程序的数据，这个内存空间专门给应用程序使用。

内核态：内核空间的代码可以访问所有内存空间，这个内存空间只有内核程序可以访问

应⽤程序如果需要进⼊内核空间，就需要通过系统调⽤，下⾯来看看系统调⽤的过程

![image-20220225130030376](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225130030376.png)

内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用，会产生一个中断，发生中断后，CPU会中断当前正在执行的用户程序，转而跳到中断处理程序，开始执行内核程序，内核处理完后，发生一个中断，把CPU执行权限交回给用户程序，回到用户态继续工作。

> 一旦一个应用程序执行系统调用成功，其 CPU 运行状态将发生变化，由用户层的 Ring3 转移至内核层的 Ring 0
>
> - 内核层次的代码为特权指令，只能在 CPU 的 Ring 0 状态下运行



### **用户空间 & 内核空间**

操作系统为了保护危险指令不被应用程序直接访问，则将虚拟空间划分为内核空间和用户空间。

- 内核空间：是操作系统的核心，它提供操作系统的最基本的功能，是操作系统工作的基础，它负责管理系统的进程、内存、设备驱动程序、文件和网络系统，决定着系统的性能和稳定性。

- 用户空间：非内核应用程序运行在用户空间。用户空间中的代码运行在较低的特权级别上，只能看到允许它们使用的部分系统资源，并且不能使用某些特定的系统功能，也不能直接访问内核空间和硬件设备



### **用户态** **和** **内核态** **切换**

- 内核态: 执行代码具有对底层硬件的完全且不受限制的访问，可以执行任何 CPU 指令并引用任何内存地址。

- 用户态: 只能受限的访问内存, 且不允许访问外围设备。占用 CPU 的能力被剥夺, CPU 资源可以被其他程序获取。

开始所有应用程序运行在用户空间，这个时候它是用户态。当一个任务（进程）执行系统调用而陷入内核代码中执行时，称进程处于内核态。例如，Java 中需要新建一个线程，`new Thread( Runnable ...)` 之后调用 `start()` 方法时, 看Hotspot Linux 的 JVM 源码实现，最终是调`pthread_create` 系统方法来创建的线程，这里会从用户态切换到内核态完成系统资源的分配，线程的创建。

我们常说用户态和内核态之间的切换开销比较大， 有如下几点：

- 保留用户态现场（上下文、寄存器、用户栈等）

- 复制用户态参数，用户栈切到内核栈，进入内核态

- 额外的检查（因为内核代码对用户不信任）

- 执行内核态代码

- 复制内核态代码执行结果，回到用户态

- 恢复用户态现场（上下文、寄存器、用户栈等）

所以，频繁的IO操作会频繁的造成用户态 —> 内核态 —> 用户态的切换，严重影响系统性能。



## 并行和并发的区别？

并发：对于一个CPU来说，同一时间内多个任务交替执行

并行：单位时间内，多个任务同时进行，每个任务分别在不同的CPU上执行

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225131720596.png" alt="image-20220225131720596" style="zoom:67%;" />



## 进程与线程

### 进程的概念

为了深刻描述程序动态执行过程的性质乃至更好地支持和管理多道程序的并发执行，人们引入了进程。

运行中的程序就是一个进程，它是资源分配的基本单位，是一个程序对某个数据集的执行过程。

- 一个进程实体由程序段、相关数据段和PCB构成，PCB是一个进程存在的标志，程序段是进程运行相关的程序代码，数据段则是存储程序运行过程中相关的一些数据。



### 进程的状态

**创建状态（new）:**进程正在被创建，尚未到就绪状态。

**就绪状态（ready）:**进程处于准备运行状态，进程目前获得了除CPU以外的全部资源，一旦得到CPU即可运行

**运行状态（running）:**进程正在处理器上运行

**阻塞状态（waiting）:**又称为等待状态，进程正在等待某一事件而暂停运行，如等待某I/O事件的完成，即使处理器空闲，该进程也不能运行，需要被唤醒。

**结束状态（terminated）:**进程正在从系统中消失，正常结束或者其他原因中断而退出运行。

![image-20220225132420077](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225132420077.png)

#### 状态变迁

- NULL -> 创建状态 ：⼀个新进程被创建时的第⼀个状态；
- 创建状态 -> 就绪状态：创建完毕后，获得了进程运行所需要的全部资源
- 就绪态 -> 运⾏状态：处于就绪状态的进程被操作系统的进程调度器选中后，就分配给CPU正式运行该进程
- 运⾏状态 -> 结束状态 ：当进程已经运⾏完成或出错时，会被操作系统做结束状态处理
- 运⾏状态 -> 就绪状态 ：CPU时间片用完了，操作系统会把该进程变为就绪态，接着从就绪队列选中另外⼀个进程运⾏
- 运⾏状态 -> 阻塞状态：当进程请求某个事件且必须等待时，例如请求 I/O 事件；
- 阻塞状态 -> 就绪状态 ：当进程要等待的事件完成时，该事件会唤醒阻塞的线程，使它从阻塞状态变到就绪状态；

如果有⼤量处于阻塞状态的进程，进程可能会占⽤着物理内存空间，显然不是我们所希望的，毕竟物理内存空间是有限的，被阻塞状态的进程占⽤着物理内存就⼀种浪费物理内存的⾏为。
所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运⾏的时候，再从硬盘换⼊到物理内存。

那么，就需要⼀个新的状态，来**描述进程没有占⽤实际的物理内存空间的情况，这个状态就是挂起状态**。这跟阻塞状态是不⼀样，阻塞状态是等待某个事件的返回。

- 阻塞挂起状态：进程在外存（硬盘）并等待某个事件的出现
- 就绪挂起状态：进程在外存（硬盘），但只要进⼊内存，即刻⽴刻运⾏

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225133001580.png" alt="image-20220225133001580" style="zoom:67%;" />

导致进程挂起的原因不只是因为进程所使⽤的内存空间不在物理内存，还包括如下情况：

- 通过 sleep 让进程间歇性挂起，其⼯作原理是设置⼀个定时器，到期后唤醒进程。
- ⽤户希望挂起⼀个程序的执⾏，⽐如在 Linux 中⽤ `Ctrl+Z` 挂起进程；



### PCB

在操作系统中，是⽤进程控制块（process control block ， PCB）数据结构来描述进程的。

**进程描述信息：**

- 进程标识符：标识各个进程，每个进程都有一个并且唯一的标识符；
- 用户标识符：进程归属的用户，用户标识符主要为共享和保护服务；

**进程控制和管理信息：**

- 进程当前状态，如 new、ready、running、waiting 或 terminated 等；

- 进程优先级：进程抢占 CPU 时的优先级；

**资源分配清单：**
有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息。
**CPU 相关信息：**
CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的PCB 中，以便进程重新执行时，能从断点处继续执行。

![image-20220904165050794](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220904165050794.png)

![image-20220904165104540](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220904165104540.png)



#### PCB是如何组织的？

通常是通过**链表**的⽅式进⾏组织，把具有**相同状态的进程链在⼀起，组成各种队列**

- 将所有处于就绪队列的进程链在一起，称为就绪队列

- 把所有因等待某事件而处于等待状态的进程链在一起组成各种阻塞队列

  <img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225133536543.png" alt="image-20220225133536543" style="zoom:67%;" />





### CPU上下文切换

任务是交给 CPU 运⾏的，那么在每个任务运⾏前，CPU 需要知道任务从哪⾥加载，⼜从哪⾥开始运⾏。

所以，操作系统需要事先帮 CPU 设置好 **CPU 寄存器和程序计数器。**

CPU 寄存器和程序计数是 CPU 在运⾏任何任务前，所必须依赖的环境，这些环境就叫做 **CPU上下⽂**

**CPU 上下⽂切换**就是先把前⼀个任务的 CPU 上下⽂（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下⽂到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务。

- 系统内核会存储保持下来的上下⽂信息，当此任务再次被分配给 CPU 运⾏时，CPU 会重新加载这些上下⽂，这样就能保证任务原来的状态不受影响，**让任务看起来还是连续运⾏。**



### 进程的上下文切换

各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执⾏，那么这个⼀个进程切换到另⼀个进程运⾏，称为**进程的上下文切换**。

进程是由内核管理和调度的，所以进程的切换只能发⽣在内核态。

**进程的上下文切换不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源。**

通常，会把**交换的信息保存在进程的 PCB**，当要运⾏另外⼀个进程的时候，我们需要从这个进程的 PCB取出上下⽂，然后恢复到 CPU 中，这使得这个进程可以继续执⾏，如下图所示

![image-20220225134444181](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220225134444181.png)

- 把处理器分配给进程，即进程上下文切换。（需要保存之前运行在处理器的进程的相关上下文，和载入现在要运行进程的相关上下文，这些上下文都在PCB中）

![image-20220904195805726](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220904195805726.png)



### 线程的概念

线程是进程当中的一条执行流程。同一个进程内多个线程可以共享进程的代码段，数据段，打开的文件资源等，但每一个线程又有自己的寄存器和栈，这样可以确保线程的控制流是相对独立的，线程是CPU调度的最小单位

- 引入线程的目的主要是为了减小并发执行时所付出的时空开销，提高操作系统的并发性能

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226102024491.png" alt="image-20220226102024491" style="zoom:67%;" />



### 线程的优缺点

优点：

- 一个进程中的线程可以共享代码段、数据段和文件资源
- 一个进程中可以有多个线程
- 各个线程可以并发执行，线程上下文切换的开销小

缺点：

- 当线程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃。比如说Java中Main线程由于异常崩溃了，那么Java进程就结束了



### 进程与线程的比较

- 进程是资源分配的单位，线程是CPU调度的单位
- 进程之间可以并发执行，线程之间也可以并发执行，线程的引入提高了操作系统的并发性，系统资源的利用率和系统的吞吐量
- 进程拥有一个完整的资源平台，而线程只是独享必不可少的资源（寄存器，栈），而一个进程中的线程可以共享进程的代码段、数据段和文件资源。
- **线程同样有准备，就绪，阻塞三种基本状态，状态转换和进程一致**
- 系统开销问题：
  - 线程能减少并发执行的时间和空间开销（线程上下文切换资源消耗小）
  - 创建和撤销进程时，系统都要分配或者回收PCB以及其他资源（内存空间，I/O设备等），所付出的开销明显大于线程创建或者撤销时的开销

- 从下图可以看出：一个进程中可以有多个线程，多个线程共享进程的**堆**和**方法区 (JDK1.8 之后的元空间)**资源，但是每个线程有自己的**程序计数器、虚拟机栈 和 本地方法栈。**

![image-20220226102835943](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226102835943.png)



### 线程上下文切换

线程与进程最大的区别在于：线程是调度的基本单位，而进程则是资源拥有的基本单位。

- 当两个线程不是属于同⼀个进程，则切换的过程就跟进程上下⽂切换⼀样；
- 当两个线程是属于同⼀个进程，因为虚拟内存是共享的，所以在切换时，虚拟内存、全局变量这些资源就保持不动，只需要切换线程的私有数据、寄存器、栈等不共享的数据；



### 进程间通信

#### 为什么需要IPC？

举例说明，`ps -ef | grep redis`

该命令由两部分组成，管道符号|左边列出所有正在运行的进程和内核线程，而|右边，用于查找是否包含了字符串“redis”,左边的输出变为了右边的输入，考虑两个命令在Shell中被执行，会分别对应两个进程，在这里管道就起到在两个进程之间转移数据的作用，也即IPC。

**若没有IPC的话，上述过程应如何做？可能的情况，利用Shell重定向输出，将ps的结果写入一个临时文件，再利用grep对临时文件进行读取、分析和输出。这里涉及到多个I/O操作，性能肯定很差。**



每个进程各自有不同的用户地址空间，任何一个进程的全局变量在另一个进程中都看不到，所以进程之间要交换数据必须经过一个媒介，这个媒介，内核缓冲区就很合适，在内核开辟一块缓冲区，进程1把数据从用户空间拷贝到内核缓冲区，进程2再从内核缓冲区把数据读走，内核提供的这种机制就是 IPC**（进程间通信（Inter Process Communication））**

![image-20220226221443256](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226221443256.png)



#### 管道

```c
#include <stdlib.h>
#include <string.h>
#include<stdio.h>
int main() {
	int p1, fd[2];
	char outpile[50]; //定义读缓冲区
	char inpile[50]; //定义写缓冲区
	pipe(fd);   //创建无名管道fd
	while ((p1 = fork()) == -1);
	if (p1 == 0) {  //子进程返回
		strcpy(inpile, "this is a message!");
		write(fd[1], inpile, 50);  //写信息到管道
		exit(0);
	}
	else {  //父进程返回
		wait(0);  //等待子进程终止
		read(fd[0], outpile, 50);  //从管道读信息到读缓冲区
		printf("%s\n", outpile); //显示读到的信息
		exit(0);
	}
}
```

`ps -ef | grep redis`， | 竖线就是一个管道，功能就是将前一个命令的输出作为后一个命令的输入，可以看到这个管道传输数据是单向的，要想相互通信，需要两个管道才行，**|称为匿名管道**。

管道还有另一个类型叫做有名管道，又叫做FIFO，因为数据是先进先出的方式。

在使⽤有名管道前，先需要通过 mkfifo 命令来创建，并且指定管道名字：`mkfifo myPipe`

myPipe 就是这个管道的名称，基于 Linux ⼀切皆⽂件的理念，所以管道也是以⽂件的⽅式存在，我们可以⽤ ls 看⼀下，这个⽂件的类型是 p，也就是 pipe（管道） 的意思：

```bash
[root@VarerLeet2 linux-course]# mkfifo myPipe
[root@VarerLeet2 linux-course]# ll
prw-r--r--. 1 root root    0 2月  26 22:04 myPipe
[root@VarerLeet2 linux-course]# echo "hello" > myPipe   //给管道输入数据，发现命令行卡住了

```

**输入给命名管道的数据，如果没有被读取的话，命令不会退出，这时候可以开另一个窗口将数据读出来，cat，命令就会退出了**

**可以看到，管道这种通信⽅式效率低，不适合进程间频繁地交换数据**

匿名管道的创建，需要通过下⾯这个系统调⽤：

- `int pipe(int fd[2])`
- fd[0]是读端，fd[1]是写端，这个匿名管道存在于内存中，不存于文件系统

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226220824426.png" alt="image-20220226220824426" style="zoom:67%;" />

可以看到，这两个描述符都是在⼀个进程⾥⾯，并没有起到进程间通信的作⽤，怎么样才能使得管道是跨过两个进程的呢？

我们可以使⽤ **fork** 创建⼦进程，创建的⼦进程会复制⽗进程的⽂件描述符，这样就做到了两个进程各有两个「 fd[0] 与 fd[1] 」，两个进程就可以通过各⾃的 fd 写⼊和读取同⼀个管道⽂件实现跨进程通信。

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226220957970.png" alt="image-20220226220957970" style="zoom:67%;" />

管道只能⼀端写⼊，另⼀端读出，所以上⾯这种模式容易造成混乱，因为⽗进程和⼦进程都可以同时写⼊，也都可以读出。那么，为了避免这种情况，通常的做法是：

- ⽗进程关闭读取的 fd[0]，只保留写⼊的 fd[1]；
- ⼦进程关闭写⼊的 fd[1]，只保留读取的 fd[0]；

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226221046571.png" alt="image-20220226221046571" style="zoom:67%;" />

**所以说如果需要双向通信，则应该创建两个管道。**

到这⾥，仅仅解析了使⽤管道进⾏⽗进程与⼦进程之间的通信，但是在我们 shell ⾥⾯并不是这样的。

在 shell ⾥⾯执⾏ A | B 命令的时候，A 进程和 B 进程都是 shell 创建出来的⼦进程，A 和 B 之间不存在⽗⼦关系，**它俩的⽗进程都是 shell**。

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226221146351.png" alt="image-20220226221146351" style="zoom:67%;" />

所以说，在 shell ⾥通过「 | 」匿名管道将多个命令连接在⼀起，实际上也就是创建了多个⼦进程，那么在我们编写 shell 脚本时，能使⽤⼀个管道搞定的事情，就不要多⽤⼀个管道，这样可以减少创建⼦进程的系统开销。

- 我们可以得知，对于匿名管道，它的通信范围是存在⽗⼦关系的进程。因为管道没有实体，也就是没有管道⽂件，只能通过 fork 来复制⽗进程 fd ⽂件描述符，来达到通信的⽬的。
- 对于有名管道，它可以在不相关的进程间也能相互通信。因为有名管道，提前创建了⼀个类型为管道的设备⽂件，在进程⾥只要使⽤这个设备⽂件，就可以相互通信。
- **不管是匿名管道还是命名管道，进程写⼊的数据都是缓存在内核中，另⼀个进程读取数据时候⾃然也是从内核中获取，同时通信数据都遵循先进先出原则**



#### 消息队列

```c
//sndfile.c
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<unistd.h>
#include<sys/types.h>
#include<linux/msg.h>

#define MAXMSG 512
struct my_msg //定义消息缓冲区数据结构
{
        long int my_msg_type;
        int i;
        char some_text[MAXMSG];

}msg;

int main() {
        int msgid; //定义消息缓冲区内部标识
        char buffer[BUFSIZ];  //定义用户缓冲区
        msgid = msgget(12, 0666 | IPC_CREAT); //创建消息队列,key为12
        while (1) {
                puts("Enter some text:"); //提示键入消息内存
                fgets(buffer, BUFSIZ, stdin); //标准输入送buffer
                msg.i++;
                printf("i=%d\n", msg.i);
                msg.my_msg_type = 3;
                strcpy(msg.some_text, buffer); //buffer中的内容送消息缓冲
                msgsnd(msgid, &msg, MAXMSG, 0); //发送消息到消息队列
                if (strncmp(msg.some_text, "end", 3) == 0) break;
        }
        exit(0);
}
```

```c
//Rcvfile.c
#include<stdio.h>
#include<stdlib.h>
#include<string.h>
#include<unistd.h>
#include<sys/types.h>
#include<linux/msg.h>
#define MAXMSG 512
struct my_msg //定义消息缓冲区数据结构
{
        long int my_msg_type;
        int i;
        char some_text[MAXMSG];
} msg;
main()
{
        int msgid;
        msg.my_msg_type = 3;
        msgid = msgget(12, 0666|IPC_CREAT); //获取消息队列， key为12
        while(1)
        {
                msgrcv(msgid, &msg, BUFSIZ, msg.my_msg_type, 0); //接收消息
                printf("You wrote: %s and i = %d\n", msg.some_text, msg.i); //显示
                if(strncmp(msg.some_text,"end",3) == 0)//消息为end则结束
                        break;
        }
        msgctl(msgid, IPC_RMID, 0); //删除消息队列
        exit(0);
}
```

前⾯说到管道的通信⽅式是效率低的，因此管道不适合进程间频繁地交换数据。

对于这个问题，消息队列的通信模式就可以解决。⽐如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。同理，B 进程要给 A 进程发送消息也是如此。

**消息队列是保存在内核中的消息链表。用户需要自定义消息的数据类型，因此每个消息体都是固定大小的存储块，如果进程从消息队列中读取了这个消息，内核就把这个消息删除，如果没有释放消息或者没有关闭操作系统，这个消息会一直存在**

**消息队列不适合比较大的数据传输，因为消息队列通信过程中，存在⽤户态与内核态之间的数据拷⻉开销**，因为进程写⼊数据到内核中的消息队列时，会发⽣从⽤户态拷⻉数据到内核态的过程，同理另⼀进程读取内核中的消息数据时，会发⽣从内核态拷⻉数据到⽤户态的过程。



#### 共享内存

```c
/*共享内存的发送程序 sndshm.c，先运行发送程序，再运行接收程序*/
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include<unistd.h>
#include <sys/types.h>
#include <sys/shm.h>
int main() {
    int shmid;
    /*共享内存的内部标识*/
    char *viraddr;
    /*定义附接到共享内存的虚拟地址*/
    char buffer[BUFSIZ];
    /*创建共享内存*/
    shmid = shmget(1234, BUFSIZ, 0666|IPC_CREAT);
    /*附接到进程的虚拟地址空间*/
    viraddr = (char *)shmat(shmid, 0, 0);
    /*循环输入信息，直到输入 end 结束*/
    while(1) {
        puts("Enter some text:");
        fgets(buffer, BUFSIZ, stdin);
        strcat(viraddr, buffer);
        /*追加到共享内存*/
        if(strncmp(buffer, "end", 3) ==0)
        break;
    }
    shmdt(viraddr);
    /*断开链接*/
    return 0;
}
```

```c
/*共享内存的接收进程程序 rcvshm.c*/
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>
#include <sys/types.h>
#include <sys/shm.h>
int main() {
    int shmid;
    char *viraddr;
    /*获取共享内存*/
    shmid = shmget(1234, BUFSIZ, 0666|IPC_CREAT);
    /*附接到进程的虚拟地址空间*/
    viraddr = (char *)shmat(shmid, 0, 0);
    /*打印信息内容*/
    printf("your message is :\n %s", viraddr);
    /*断开链接*/
    shmdt(viraddr);
    /*撤销共享内存*/
    shmctl(shmid, IPC_RMID, 0);
    return 0;
}
```

**管道、消息队列的读取和写⼊的过程，都会有发⽣⽤户态与内核态之间的消息拷⻉过程**。那共享内存的⽅式，就很好的解决了这⼀问题。

现代操作系统，对于内存管理，采⽤的是**虚拟内存技术**，也就是每个进程都有⾃⼰独⽴的虚拟内存空间，不同进程的虚拟内存映射到不同的物理内存中。所以，即使进程 A 和 进程 B 的虚拟地址是⼀样的，其实访问的是不同的物理内存地址，对于数据的增删查改互不影响。

**共享内存的机制，就是拿出⼀块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写⼊的东⻄，另外⼀个进程⻢上就能看到了，都不需要拷⻉来拷⻉去，传来传去，⼤⼤提⾼了进程间通信的速度。

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226222405814.png" alt="image-20220226222405814" style="zoom:67%;" />



#### 信号量

⽤了共享内存通信⽅式，带来新的问题，那就是如果多个进程同时修改同⼀个共享内存，很有可能就冲突了。例如两个进程都同时写⼀个地址，那先写的那个进程会发现内容被别⼈覆盖了。
为了防⽌多进程竞争共享资源，⽽造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被⼀个进程访问。正好，**信号量就实现了这⼀保护机制**。

**信号量其实是⼀个整型的计数器，主要⽤于实现进程间的互斥与同步，⽽不是⽤于缓存进程间通信的数据。**

信号量表示资源的数量，控制信号量的⽅式有两种原⼦操作：

- P（）：这个操作会把信号量减去 1，相减后如果信号量 < 0，则表明资源已被占⽤，进程需阻塞等待；相减后如果信号量 >= 0，则表明还有资源可使⽤，进程可正常继续执⾏。
- V（）：这个操作会把信号量加上 1，相加后如果信号量 <= 0，则表明当前有阻塞中的进程，于是会将该进程唤醒运⾏；相加后如果信号量 > 0，则表明当前没有阻塞中的进程

##### 互斥信号量

如果要使得两个进程互斥访问共享内存，我们可以初始化信号量为 1 ，信号初始化为 1 ，就代表着是互斥信号量，它可以保证共享内存在任何时刻只有⼀个进程在访问，这就很好的保护了共享内存

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226222938637.png" alt="image-20220226222938637" style="zoom:67%;" />

##### 同步信号量

在多进程⾥，每个进程并不⼀定是顺序执⾏的，它们基本是以各⾃独⽴的、不可预知的速度向前推进，但有时候我们⼜希望多个进程能密切合作，以实现⼀个共同的任务。

例如，进程 A 是负责⽣产数据，⽽进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A必须先⽣产了数据，进程 B 才能读取到数据，所以执⾏是有前后顺序的。

那么这时候，就可以⽤信号量来实现多进程同步的⽅式，我们可以初始化信号量为 0 。

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226223029756.png" alt="image-20220226223029756" style="zoom:67%;" />

#### 信号

可以通过`kill -l`查看所有信号

```bash
[root@VarerLeet2 linux-course]# kill -l
 1) SIGHUP	 2) SIGINT	 3) SIGQUIT	 4) SIGILL	 5) SIGTRAP
 6) SIGABRT	 7) SIGBUS	 8) SIGFPE	 9) SIGKILL	10) SIGUSR1
11) SIGSEGV	12) SIGUSR2	13) SIGPIPE	14) SIGALRM	15) SIGTERM
16) SIGSTKFLT	17) SIGCHLD	18) SIGCONT	19) SIGSTOP	20) SIGTSTP
21) SIGTTIN	22) SIGTTOU	23) SIGURG	24) SIGXCPU	25) SIGXFSZ
26) SIGVTALRM	27) SIGPROF	28) SIGWINCH	29) SIGIO	30) SIGPWR
31) SIGSYS	34) SIGRTMIN	35) SIGRTMIN+1	36) SIGRTMIN+2	37) SIGRTMIN+3
38) SIGRTMIN+4	39) SIGRTMIN+5	40) SIGRTMIN+6	41) SIGRTMIN+7	42) SIGRTMIN+8
43) SIGRTMIN+9	44) SIGRTMIN+10	45) SIGRTMIN+11	46) SIGRTMIN+12	47) SIGRTMIN+13
48) SIGRTMIN+14	49) SIGRTMIN+15	50) SIGRTMAX-14	51) SIGRTMAX-13	52) SIGRTMAX-12
53) SIGRTMAX-11	54) SIGRTMAX-10	55) SIGRTMAX-9	56) SIGRTMAX-8	57) SIGRTMAX-7
58) SIGRTMAX-6	59) SIGRTMAX-5	60) SIGRTMAX-4	61) SIGRTMAX-3	62) SIGRTMAX-2
```

运⾏在 shell 终端的进程，我们可以通过键盘输⼊某些组合键的时候，给进程发送信号。例如

- Ctrl+C 产⽣ SIGINT 信号，表示终⽌该进程
- Ctrl+Z 产⽣ SIGTSTP 信号，表示停⽌该进程，但还未结束

如果进程在后台运⾏，可以通过 kill 命令的⽅式给进程发送信号

- kill -9 1050 ，表示给 PID 为 1050 的进程发送 SIGKILL 信号，⽤来⽴即结束该进程；



#### Socket

管道、消息队列、共享内存、信号量、信号都是在同一台主机进行进程间通信，想要跨网络与不同主机上的进程通信，就需要Socket通信了。Socket也可以进行本地通信。

##### 针对 TCP 协议通信的 socket 编程模型

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220226223637945.png" alt="image-20220226223637945" style="zoom:67%;" />

- 服务端和客户端初始化 socket ，得到⽂件描述符；
- 服务端调⽤ bind ，将绑定在 IP 地址和端⼝;
- 服务端调⽤ listen ，进⾏监听；
- 服务端调⽤ accept ，等待客户端连接；
- 客户端调⽤ connect ，向服务器端的地址和端⼝发起连接请求；
- 服务端 accept 返回⽤于传输的 socket 的⽂件描述符
- 客户端调⽤ write 写⼊数据；服务端调⽤ read 读取数据；
- 客户端断开连接时，会调⽤ close ，那么服务端 read 读取数据的时候，就会读取到了 EOF ，待处理完数据后，服务端调⽤ close ，表示连接关闭。

##### 针对本地进程间通信的 socket 编程模型

本地字节流 socket 和 本地数据报 socket 在 bind 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端⼝，⽽是绑定⼀个**本地⽂件**，这也就是它们之间的最⼤区别。



### 线程间同步的方式

因为线程是进程中的一条执行流程，线程是共享进程的资源的，线程同步是两个或多个共享关键资源的线程的并发执行。应该同步线程以避免关键的资源使用冲突。操作系统一般有下面三种线程同步的方式：

- **互斥量（mutex）**：只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。比如 Java 中的 synchronized 关键词和各种 Lock 都是这种机制。
- **信号量（Semaphore）**:它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。
- **事件（Event）:Wait/Notify**，通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。



### 进程的调度算法

**先到先服务(FCFS)调度算法** : 从就绪队列中选择一个最先进入该队列的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。作业调度或者进程调度均可

- <img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227112953823.png" alt="image-20220227112953823" style="zoom:50%;" />

- 若一个长作业先运行了，就会对后面短作业不利
- FCFS 对⻓作业有利，适⽤于 CPU 繁忙型作业的系统，⽽不适⽤于 I/O 繁忙型作业的系统。

**短作业优先(SJF)的调度算法** : 从就绪队列中选出一个估计运行时间最短的进程为之分配资源，使它立即执行并一直执行到完成或发生某事件而被阻塞放弃占用 CPU 时再重新调度。作业调度或者进程调度均可

- <img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227113001622.png" alt="image-20220227113001622" style="zoom:50%;" />
- 显然对长作业不利

**高响应比优先调度算法：**每次进⾏进程调度时，先计算「响应⽐优先级」，然后把「响应⽐优先级」最⾼的进程投⼊运⾏，作业调度或者进程调度均可

- <img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227113054032.png" alt="image-20220227113054032" style="zoom:50%;" />
- 若等待时间相同的话，短作业优先
- 若运行时间相同的话，等待久的优先执行

**时间片轮转调度算法** : 时间片轮转调度是一种最古老，最简单，最公平且使用最广的算法，又称 RR(Round robin)调度。每个进程被分配一个时间段，称作它的时间片，即该进程允许运行的时间。进程调度

- <img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227113327356.png" alt="image-20220227113327356" style="zoom:50%;" />
- 这里时间片的选择就很关键
  - 如果时间片太短的话，会导致过多的进程上下文切换，降低了CPU效率
  - 如果时间片太长了的话，又变成了先来先服务算法

**优先级调度** ： 为每个进程分配优先级，首先执行具有最高优先级的进程，依此类推。具有相同优先级的进程以 FCFS 方式执行。可以根据内存要求，时间要求或任何其他资源要求来确定优先级。作业调度或者进程调度均可

- 该算法也有两种处理优先级⾼的⽅法，⾮抢占式和抢占式：
  - ⾮抢占式：当就绪队列中出现优先级⾼的进程，运⾏完当前进程，再选择优先级⾼的进程。
  - 抢占式：当就绪队列中出现优先级⾼的进程，当前进程挂起，调度优先级⾼的进程运⾏。
- 该算法可能导致优先级低的一直得不到运行而饿死

**多级反馈队列调度算法** ：进程调度

- 「多级」表示有多个队列，每个队列优先级从⾼到低，同时优先级越⾼时间⽚越短。
- 「反馈」表示如果有新的进程加⼊优先级⾼的队列时，⽴刻停⽌当前正在运⾏的进程，转⽽去运⾏优先级⾼的队列；

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227113603755.png" alt="image-20220227113603755" style="zoom:50%;" />

- 新的进程会放在第一级队列末尾，按照先来先服务原则调度，若在第一级队列没有运行完成，放入第二级队列末尾，若在最后一级队列没有运行完成，则按照时间片轮转，在最后一级队列调度
- 该算法很好的兼顾了长作业和短作业，同时有较好的响应时间。



### 死锁

若系统中存在一组进程/线程，它们中的每一个进程/线程都占有了某种资源而又在同在其中另一进程所占有的资源，这种等待永远不会结束，就说系统出现了死锁。

死锁产生的原因：

- 系统资源存在竞争，若系统中的资源数大于进程的总需求，那么就不会有死锁问题了
- 进程推进顺序非法，也就是请求和释放资源的顺序不对。

死锁需要同时满足以下四个必要条件：

- 互斥条件: 进程应该互斥使用资源，任一时刻一个资源仅为一个进程独占。
- 占有且等待：一个进程请求资源得不到而等待时，不释放已经占有的资源。
- 不剥夺条件: 任一进程不能从另一进程那里抢夺资源，即已被占有的资源，只能由占用进程释放。
- 循环等待条件：存在一个循环等待链，每一个进程分别等待另一个进程所持有的资源，造成永久等待。

循环等待条件和死锁的定义一样？有什么区别么。

死锁已经是一种僵局，若没有外力作用，无法继续推进下去了，但是循环等待，看这个例子

![image-20220904210654736](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220904210654736.png)

- Pn等待的资源可以由Pk给（Pk不属于循环等待圈子里的进程），也可以由P0给，若Pk给了资源，那么循环等待就结束了
  - 因此，循环等待只是死锁的一个必要条件。

**顺带看另外一个，资源分配图含有圈，但系统不一定有死锁，原因就是，同类资源数大于1**

```java
import java.util.concurrent.TimeUnit;
public class DeadLock {

    private final Object objA = new Object();

    private final Object objB = new Object();

    public void threadMethod(){
        new Thread(() -> {
            synchronized (objA){
                try { TimeUnit.MILLISECONDS.sleep(10); }
                catch (InterruptedException e) { e.printStackTrace(); }
                synchronized (objB){
                    System.out.println("拿到两个锁...");
                }
            }
        },"AAA").start();

        new Thread(() -> {
            synchronized (objB){
                try { TimeUnit.MILLISECONDS.sleep(10); }
                catch (InterruptedException e) { e.printStackTrace(); }
                synchronized (objA){
                    System.out.println("拿到两个锁...");
                }
            }
        },"BBB").start();
    }
}
```

```bash
javac DeadLock.java
java DeadLock
出现死锁,如何排查?
jps -l 查看进程号,jstack排查死锁
jps -l
jstack 10624

Found one Java-level deadlock:
=============================
"BBB":
  waiting to lock monitor 0x00000242e241dc58 (object 0x00000000d5ce00b0, a java.lang.Object),
  which is held by "AAA"
"AAA":
  waiting to lock monitor 0x00000242e24206f8 (object 0x00000000d5ce00c0, a java.lang.Object),
  which is held by "BBB"

Java stack information for the threads listed above:
===================================================
"BBB":
        at DeadLock.lambda$threadMethod$1(DeadLock.java:24)
        - waiting to lock <0x00000000d5ce00b0> (a java.lang.Object)
        - locked <0x00000000d5ce00c0> (a java.lang.Object)
        at DeadLock$$Lambda$2/303563356.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)
"AAA":
        at DeadLock.lambda$threadMethod$0(DeadLock.java:14)
        - waiting to lock <0x00000000d5ce00c0> (a java.lang.Object)
        - locked <0x00000000d5ce00b0> (a java.lang.Object)
        at DeadLock$$Lambda$1/531885035.run(Unknown Source)
        at java.lang.Thread.run(Thread.java:748)

Found 1 deadlock.
```



### 解决死锁的方法

产生死锁要同时满足互斥条件、占有且等待、不剥夺条件和循环等待条件，只需要破坏其中一个条件即可。或者允许死锁发生，但当死锁发生时，能够检测出死锁并有能力实现恢复

#### 预防

由于互斥条件是一个比较基础的条件，有些资源不能被同时访问，所以**破坏互斥条件不太可行。**

破坏不剥夺条件会比较复杂，释放已获得的资源可能会造成一些意想不到的后果，一般也不考虑。

**静态分配策略：**一个进程在执行前就申请它所要的全部资源，直到它所要的资源都满足才执行

- **破坏了占有且等待**
- 优点：实现简单
- 缺点：严重降低了资源利用率

**按序分配策略：**按一定的顺序，申请资源，如上面的死锁代码中，两个线程申请资源的顺序不一致，这个顺序不一致导致了死锁

- **破坏了循环等待条件**



#### 避免

破坏死锁的四个必要条件之一能预防系统发生死锁，但这会导致进程运行和资源使用率。

避免死锁就是在资源的动态分配过程中，用某种方法防止系统进入不安全状态。

> 安全状态:能保证所有进程在有限时间内得到需要的全部资源，则称系统处于安全状态
>
> **系统调用银行家算法进行安全检查时，只要找到一个安全序列就可判断系统是安全的。**

银行家算法：

1. 进程首次申请资源时，测试该进程对资源的最大需求量，如果系统现存的资源可以满足它的最大需求量则按当次的申请量进行分配，否则拒绝分配
2. 当进程在执行中继续申请资源时，测试该进程已占用的资源数+本次申请的资源数是否超过了该进程对资源的最大需求量，若超过则拒绝分配。
3. 若没有超过的话，再测试系统现存的资源能否满足该进程目前还需要的需求量，若满足则按当次的申请量分配资源，否则也要推迟。
4. 这样做可以保证任意时候有一个进程可以得到所需要的全部资源而执行结束，执行结束后释放资源，又可以满足下一进程的资源需求，保证了所有进程在有限的时间得到需要的资源。



## 虚拟内存

### 为什么要引入虚拟内存？

多道程序的并发执行不仅让进程之间共享了处理器，还共享了内存，而要运行很多进程的话，就需要很多的内存，当一个程序没有足够内存空间的时候，它显然不能运行，因此，就需要在物理内存有限的情况下，尝试着在逻辑上扩充内存，因此引入了虚拟内存。



### 什么是虚拟内存？

- **虚拟内存为每个进程提供了一个一致的、私有的内存空间，它让每个进程产生了一种自己在独显主存的错觉（每个进程都有一片连续的内存空间）**
- **保护了每个进程的地址空间，不被他人破坏**
- 虚拟内存还可以把内存扩展到硬盘空间，用到这一部分的时候再利用页面置换算法装入内存（请求分页式存储管理）
- 操作系统引入了虚拟内存，进程持有的虚拟地址会通过CPU芯片中的**内存管理单元（MMU）**的映射，来转变为物理地址，然后再通过物理地址访问内存

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227100224316.png" alt="image-20220227100224316" style="zoom:67%;" />

### 局部性原理

局部性原理是虚拟内存技术的基础，正是因为程序运行具有局部性原理，才可以只装入部分程序到内存就开始运行。

- **时间局部性：**如果程序中某条指令开始执行，不久后该指令可能再次执行，如果某数据被访问，不久后该数据可能再次被访问（for循环）
- **空间局部性：**一旦程序访问了某存储单元，不久后，它相邻的存储单元也将被访问（数组、栈、队列、链表等）



### 虚拟存储器

基于**局部性原理**，在程序装入时，可以**将程序的一部分装入内存**，而将其他部分留在外存，就可以启动程序执行。由于外存往往比内存大很多，所以我们运行的软件的内存大小实际上是可以比计算机系统实际的内存大小大的。在程序执行过程中，当所访问的信息不在内存时，由操作系统将所需要的部分调入内存，然后继续执行程序。另一方面，操作系统将内存中暂时不使用的内容换到外存上，从而腾出空间存放将要调入内存的信息。这样，计算机好像为用户提供了一个比实际内存大的多的存储器——**虚拟存储器**。

三个特征：

- 多次性：作业无需一次全部装入、只需要将当前运行需要的那部分程序和数据装入内存即可。
- 对换性：作业运行的时候无需常驻内存，允许将那些暂时不用的程序和数据段从内存换出到外存，需要的时候再从外存调至内存
- 虚拟性：即从逻辑上扩充内存的容量，使用户所看到的内存容量远大于实际的内存容量。



### 虚拟内存技术的实现

**虚拟内存的实现需要建立在离散分配的内存管理方式的基础上。** 

虚拟内存的实现需要以下几个方面的支持：

- 一定容量的内存和外存
- 页表机制，作为主要的数据结构
- 中断机构，当用户程序要访问的部分尚未调入内存时，则产生中断
- 地址变换机构，逻辑地址到物理地址的变换。

虚拟内存的实现有以下三种方式：

- 请求分页式存储管理（页面置换算法）:**建立在页式存储管理**之上，为了支持虚拟存储器功能而增加了请求分页功能和页面置换功能。请求分页式存储管理允许作业只装入部分页面就启动运行，在执行过程中，如果所要访问的页已调入主存，则进行地址转换得到欲访问的主存物理地址；如果所要访问的页面不在主存，则产生一个缺页中断，如果此时主存能容纳新页，则启动磁盘I/O将其调入主存；如果主存已满，则通过页面置换功能将当前所需的页面调入。

  - 请求分页式存储管理的主要依据就是页表。由于只是将作业的部分页面调入主存，其余部分仍存放在辅存上，因此必须指出哪些页面已在主存，哪些页面还没有装入。因此，需要将页表修改如下：

  - | 页号 | 物理块号 | 状态位 | 访问字段 | 修改位 | 辅存地址 |
    | ---- | -------- | ------ | -------- | ------ | -------- |

  - 状态位用来指出该页是否已经调入主存（1：已经调入，0：还未调入）

  - 物理块号指出了该页在主存中的占用块，辅存地址指明了该页在磁盘上的地址。

- 请求分段式存储管理

- 请求段页式存储管理

> 请求分页式存储管理和分页管理的根本区别就是是否将程序全部装入内存

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227101527160.png" alt="image-20220227101527160" style="zoom: 50%;" />



#### 页面置换算法

地址映射过程中，若所要访问的页面不在内存中，则发生缺页中断。

> 当发生缺页中断时，如果当前内存中并没有空闲的页面，操作系统就必须在内存选择一个页面将其移出内存，以便为即将调入的页面让出空间。用来选择淘汰哪一页的规则叫做页面置换算法，我们可以把页面置换算法看成是淘汰页面的规则。



**抖动：**刚刚换出的页面又马上要换入主存，刚刚换入的页面又马上要换出主存，这种频繁的页面调度行为称为抖动。

一个好的置换算法应该尽量减少抖动。



##### 缺页中断处理流程

当 CPU 访问的⻚⾯不在物理内存时，便会产⽣⼀个缺⻚中断，请求操作系统将所缺⻚调⼊到物理内存。那它与⼀般中断的主要区别在于：

- 缺⻚中断在指令执⾏「期间」产⽣和处理中断信号，⽽⼀般中断在⼀条指令执⾏「完成」后检查和处理中断信号。
- 缺⻚中断返回到该指令的开始重新执⾏「该指令」，⽽⼀般中断返回回到该指令的「下⼀个指令」执⾏。

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227101346483.png" alt="image-20220227101346483" style="zoom:67%;" />



##### 最佳页面置换算法（OPT）

置换在未来最长时间不访问的页面，由于无法预知哪个页面最长时间不被访问，这种算法无法实现

##### 先进先出页面置换算法（FIFO）

总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面进行淘汰。

> Belady现象：分配的页面数（物理块）越多，缺页中断次数反而增加
>
> - 没有考虑到程序执行的动态特性（局部性原理）

##### 最近最久未使用算法（LRU）

选择最近一段时间内最长时间没有被访问过的页面调出。

- 维护最长时间没有被访问的页面有几种方式
  - 基于时间，给每个页面设置一个访问字段，记录上次被访问的时间，淘汰的时候淘汰时间最长的
  - 基于链表，双向链表，表头的是最近访问的，表尾的是最近没有访问的，淘汰的时候就把表尾的淘汰就好了。

##### 时钟置换算法（Clock）

完全实现LRU比较困难，可以采用时钟置换算法，该算法的思路是，把所有的⻚⾯都保存在⼀个类似钟⾯的「环形链表」中，⼀个表针指向最⽼的⻚⾯。

当发⽣缺⻚中断时，算法⾸先检查表针指向的⻚⾯：

- 访问位是0代表最近没有被访问过

- 如果它的访问位位是 0 就淘汰该⻚⾯，并把新的⻚⾯插⼊这个位置，然后把表针前移⼀个位置；
- 如果访问位是 1 就清除访问位，并把表针前移⼀个位置，重复这个过程直到找到了⼀个访问位为 0 的⻚⾯为⽌

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227103034538.png" alt="image-20220227103034538" style="zoom:50%;" />

##### 最近最不常用置换算法（LFU）

该置换算法选择在之前时期使用最少的页面作为淘汰页。

它的实现⽅式是，对每个⻚⾯设置⼀个「访问计数器」，每当⼀个⻚⾯被访问时，该⻚⾯的访问计数器就累加 1。在发⽣缺⻚中断时，淘汰计数器值最⼩的那个⻚⾯。重置所有访问计数器。



## 内存管理

操作系统的内存管理主要负责内存的分配与回收（malloc 函数：申请内存，free 函数：释放内存），另外地址转换也就是将逻辑地址转换成相应的物理地址等功能也是操作系统内存管理做的事情。

> 操作系统引入了虚拟内存，进程持有的虚拟地址会通过CPU芯片中的**内存管理单元（MMU）**的映射，来转变为物理地址，然后再通过物理地址访问内存

简单分为**连续分配管理方式**和**非连续分配管理方式**这两种。连续分配管理方式是指为一个用户程序分配一个连续的内存空间，常见的如 **块式管理** 。同样地，非连续分配管理方式允许一个程序使用的内存分布在离散或者说不相邻的内存中，常见的如**页式管理** 和 **段式管理**。 

**为什么要进行内存管理？**

在单道系统中，一个系统在一个时间段只执行一个程序，内存分配十分简单，引入多道程序后，进程之间共享的不仅仅是处理机，还有主存储器。若共享主存的话，容易导致主存数据冲突，影响进程的并发执行，因此为了更好支持多道程序并发执行，需要内存管理。



### 连续存储管理---块式管理

#### 单一连续存储管理

内存分为系统区和用户区，系统区仅供操作系统使用，在低地址部分。

一个作业独占用户区

#### 固定分区存储管理

预先把主存中的用户区分割成若干个分区，每个分区可以相同可以不同，一旦分割完成，分区大小不可变。

- 一个分区一个作业

- 不允许一个作业跨分区存储

- 可以用主存分配表说明各分区情况

- 由于作业在执行过程中不会被改变存储区域，可以采用静态重定位装入。

- | 分区号 | 大小(KB) | 起址（KB） | 标志（0表示未使用） |
  | ------ | -------- | ---------- | ------------------- |

- 线性查表，若标志为0且大小能容纳作业，就可以分配

- **存在的问题：**

  - 程序可能太大放不进任何一个分区，就需要用覆盖技术来使用内存空间
  - 可能出现**内存碎片（内部碎片）**


> 覆盖技术的基本思想：把用户空间分为一个固定区和若干个覆盖区，经常活跃的部分放在固定区，其余部分，即将要访问的段放入覆盖区，其他段放入外存，在需要的时候再将其调入覆盖区

#### 可变分区存储管理

不预先划分用户区，而是作业要装入主存的时候，根据作业需要的地址空间大小和当时主存空间的实际使用情况决定是否为该作业分配一个分区。

- 这里主存中的分区大小是可以变化的，可以采用移动技术合并零散分区以容纳更大的作业
- 设置空闲分区表和已分配分区表来描述系统空间
- 也会产生**内存碎片（外部碎片）**
- 可变分区的分配算法：
  - 最先适应分配算法：线性扫描空闲分区表
  - 最优适应分配算法：按空闲分区长度递增排序，二分查找最小第一个
  - 最坏适应分配算法：按空闲分区长度递减排序，每次选最大的空间用来分配



可变分区中，作业执行完毕后，需要将它所占据的分区回收，有四种回收情况

![image-20220905110548938](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905110548938.png)

- 其中第四种需要在空闲分区表中新建立一个表项记录下来



### 非连续存储管理

#### 页式存储管理

![image-20220905110921159](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905110921159.png)

![image-20220905113943369](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905113943369.png)

把主存划分成大小相同的若干区域，每个区域为一块

- 把虚拟内存地址，切分成⻚号和偏移量；
- 根据⻚号，从⻚表⾥⾯，查询对应的物理⻚号；
- 直接拿物理⻚号，加上前⾯的偏移量，就得到了物理内存地址。

页表查数据要访问主存两次，可以设置快表（相联寄存器TLB），页号直接对应物理内存地址，这样只需要访问一次主存

#### 段式存储管理

程序是由若⼲个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就⽤分段（Segmentation）的形式把这些段分离出来。

- 每个段在段表中有⼀个项，通过段号在这⼀项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227110519825.png" alt="image-20220227110519825" style="zoom:50%;" />

- 如果要访问段 3 中偏移量 500 的虚拟地址，我们可以计算出物理地址为，段 3 基地址 7000 + 偏移量 500= 7500。

#### 段页式存储管理

段页式管理机制结合了段式管理和页式管理的优点。简单来说段页式管理机制就是把主存先分成若干段，每个段又分成若干页，也就是说 **段页式管理机制** 中段与段之间以及段的内部的都是离散的。

段⻚式内存管理实现的⽅式：

- 先将程序划分为多个有逻辑意义的段，也就是前⾯提到的分段机制
- 接着再把每个段划分为多个⻚，也就是对分段划分出来的连续空间，再划分固定⼤⼩的⻚；

这样，地址结构就由**段号、段内⻚号和⻚内偏移量**三部分组成。

- 第一次通过段号在段表中查页表始址
- 第二次通过页表查到物理页号
- 第三次通过物理页号和页内偏移量取数据



#### 快表和多级页表

在分页内存管理中，很重要的两点是：

- 虚拟地址到物理地址的转换要快。
- 解决虚拟地址空间大，页表也会很大的问题。



##### 快表（TLB）

为了解决虚拟地址到物理地址的转换速度，操作系统在 **页表方案** 基础之上引入了 **快表** 来加速虚拟地址到物理地址的转换。我们可以把快表理解为一种特殊的高速缓冲存储器（Cache），其中的内容是页表的一部分或者全部内容。作为页表的 Cache，它的作用与页表相似，但是提高了访问速率。由于采用页表做地址转换，读写内存数据时 CPU 要访问两次主存。有了快表，有时只要访问一次高速缓冲存储器，一次主存，这样可加速查找并提高指令执行速度。

使用快表之后的地址转换流程是这样的：

1. 根据虚拟地址中的页号查快表；
2. 如果该页在快表中，直接从快表中读取相应的物理块号，与页内偏移量拼接得到物理地址
3. 如果该页不在快表中，就访问内存中的页表，再从页表中得到物理地址，同时将页表中的该映射表项添加到快表中；
4. 当快表填满后，又要登记新页时，就按照一定的淘汰策略淘汰掉快表中的一个页。



##### 多级页表

因为每个进程都要一个对应的页表，考虑页表大小的问题。

![image-20220905113943369](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905113943369.png)

一个页面大小是4KB，页表项4B为例子，若要实现进程对全部逻辑地址的映射，那么页表需要多大？

- 4KB / 4B = 1024，一页可以存1024个页表项

- 2^20 * 4B / 4Kb = 1024页，一个进程需要1024页才能实现全部逻辑地址的映射，这大大超过了进程自身需要的页面了。

引入多级页表的主要目的是为了避免把全部页表一直放在内存中占用过多空间，特别是那些根本就不需要的页表就不需要保留在内存中。

将⻚表（⼀级⻚表）分为 1024 个⻚表（⼆级⻚表），每个表（⼆级⻚表）中包含 1024 个「⻚表项」，形成⼆级分⻚。如下图所示：

![image-20220227111537957](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227111537957.png)

> [多级页表如何节约内存 - Penguin (polarxiong.com)](https://www.polarxiong.com/archives/多级页表如何节约内存.html)



#### 分页机制和分段机制的共同点和区别

**共同点** ：

- 分页机制和分段机制都是为了提高内存利用率，减少内存碎片。
- 页和段都是离散存储的，所以两者都是离散分配内存的方式。但是，每个页和段中的内存是连续的。

**区别** ：

- 页的大小是固定的，由操作系统决定；而段的大小不固定，取决于我们当前运行的程序。
- 分页仅仅是为了满足操作系统内存管理的需求，而段是逻辑信息的单位，在程序中可以体现为代码段，数据段，能够更好满足用户的需要。
- 分页的程序地址空间是一维的，用一个逻辑地址即可表示，而分段的程序地址空间是二维的，需要给出段名或者段号，又要给出段内地址



### CPU寻址

现代处理器使用的是一种称为 **虚拟寻址(Virtual Addressing)** 的寻址方式。**使用虚拟寻址，CPU 需要将虚拟地址翻译成物理地址，这样才能访问到真实的物理内存。** 实际上完成虚拟地址转换为物理地址转换的硬件是 CPU 中含有一个被称为 **内存管理单元（Memory Management Unit, MMU）** 的硬件。如下图所示：

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220227111955872.png" alt="image-20220227111955872" style="zoom:67%;" />





## 软链接和硬链接

### inode

- node num仅在各自的文件系统内是唯一的
- 设备编号+inode num的组合在整个系统中可能是唯一的

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219182742083.png" alt="image-20211219182742083" style="zoom:67%;" />

<img src="https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219182849998.png" alt="image-20211219182849998" style="zoom: 80%;" />



### 一个40个block的文件如何存储？

![image-20211219183513655](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219183513655.png)

**若一个文件的大小大于48KB，那么Single及其以下的指针就派上用场**

![image-20211219183556484](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219183556484.png)

**( 1024 * 1024 * 1024 ) * 4KB = 4TB**

![image-20211219183622917](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219183622917.png)

### inode number

每个inode都有一个号码，操作系统用inode号码来识别不同的文件。

Unix/Linux系统内部不使用文件名，而**使用inode号码来识别文件**。对于系统来说，**文件名只是inode号码便于识别的别称或者绰号**。



### 用户通过文件名打开文件分为三步

- 系统找到这个文件名对应的inode号码
- 通过inode号码，获取inode中的文件元信息和链接信息
- 根据inode的链接信息，找到文件数据所在的block，读出数据。



### stat 查看某个文件的inode包含文件的元信息

![image-20211219185210904](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219185210904.png)

![image-20220814113008398](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220814113008398.png)



### 目录文件的构成

普通文件是inode+数据block组成

目录文件的结构是由inode+目录项block组成

通过目录项找到目录下文件的inode信息，然后就可以找到文件的block块及数据信息

![image-20211219190440395](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219190440395.png)



### 读取/etc/passwd文件的详细过程

![image-20211219191417233](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219191417233.png)



### ls命令

由于目录块存储了inode num 和文件名的关系

因此以下两个命令只需要查询目录项就可以了

```bash
[root@VarerLeet2 linux-course]# ls -i
833533 testDir
[root@VarerLeet2 linux-course]# ls 
testDir
```

而`ls -l`必须根据inode num去访问inode节点，才能得到文件的元信息

```bash
[root@VarerLeet2 linux-course]# ls -l
总用量 4
drwxr-srwx. 2 root testgroup 4096 12月 19 16:17 testDir
```

![image-20211219192215201](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219192215201.png)



### 链接文件 ln

- `ln file1 file2` 硬链接

文件名和inode号码是"一一对应"关系，每个inode号码对应一个文件名。但是，Unix/Linux系统允许，**多个文件名指向同一个inode号码。这种情况就被称为"硬链接"（hard link）**

不同的文件名访问同样的内容；

对文件内容进行修改，会影响到所有文件；

删除一个文件名，不影响另一个文件名的访问。

硬链接无法跨文件系统，因为inode号是和文件系统相关联的，因此其只能表达当前文件系统。

#### 硬链接图示

![image-20211219192502305](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219192502305.png)

#### 软链接图示

![image-20211219192603030](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211219192603030.png)



#### 一个inode num对应两个文件

```bash
[root@VarerLeet2 linux-course]# touch a.txt
[root@VarerLeet2 linux-course]# ln a.txt b.txt
[root@VarerLeet2 linux-course]# stat a.txt 
  文件："a.txt"
  大小：0         	块：0          IO 块：4096   普通空文件
设备：803h/2051d	Inode：833492      硬链接：2
权限：(0644/-rw-r--r--)  Uid：(    0/    root)   Gid：(    0/    root)
环境：unconfined_u:object_r:home_root_t:s0
最近访问：2021-12-19 19:36:54.813865194 +0800
最近更改：2021-12-19 19:36:54.813865194 +0800
最近改动：2021-12-19 19:37:06.833897519 +0800
创建时间：-
[root@VarerLeet2 linux-course]# find -inum 833492
./b.txt
./a.txt
```



#### 硬链接与链接数

•inode信息中有一项叫做"链接数"，记录指向该inode的文件名总数，这时就会增加1。删除一个文件名，就会使得inode节点中的"链接数"减1。当这个值减到0，表明没有文件名指向这个inode，系统就会回收这个inode号码，以及其所对应block区域。

–多个文件名对应到同一个inode节点

•创建目录时，默认会生成两个目录项："."和".."。前者的inode号码就是当前目录的inode号码，等同于当前目录的"硬链接"；后者的inode号码就是当前目录的父目录的inode号码，等同于父目录的"硬链接"。所以，任何一个目录的"硬链接"总数，**总是等于2加上它的子目录总数**（含隐藏目录）。

对于每个目录，`.和父目录的列表中的一个`会指向目录，以及每个子目录的`..`也会指向目录

> mkdir abc ,此时abc的链接数就是2，如果在abc目录下新建一个目录abcd，那么abc这时候的链接数是3



#### 软链接不增加链接数

`ln -s f1 f2`

- 文件f2不是映射为文件f1的inode号码，因此文件f1的inode"链接数"不会因此发生变化。

- ```bash
  [root@VarerLeet2 test]# ll -i
  总用量 0
  833539 -rw-r--r--. 1 root root 0 12月 19 19:46 f1
  833540 lrwxrwxrwx. 1 root root 2 12月 19 19:47 f2 -> f1
  ```

- 文件f2和文件f1的inode号码不一样，文件f2的内容是文件f1的路径。读取文件f2时，系统会自动将访问导向文件f1。因此，无论打开哪一个文件，最终读取的都是文件f1。



## 磁盘

### 磁盘结构

- `spindle`:轴
- `track`:磁道
- `sector`:扇区
- `cylinder`:柱面
- `platter`:盘面  盘片等于2盘面
- `arm assembly`:

![image-20211202103526515](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211202103526515.png)

磁盘被组织成磁道，磁道是单个盘片上的同心圆，**所有盘面上半径相同的磁道构成了柱面**

- 看右边的顶视图，有很多个半径不同的圆，即很多不同的同心圆 -> 很多**不同的磁道**
- 再看左边的磁盘正视图，从上往下有三个圆被虚线框起来了，它们就组成了一个**柱面**
- 盘片有上表面和下表面，**每一个面都是一个盘面**，覆盖了一层磁性材料，**二进制位就是被存储**在这里
- 再看看右边的图，黑色的线条叫做间隙，用来分隔圆，**每一小段就是一个扇区**，间隙是没有被磁化的
- 块，是在磁盘和主存之间所传输数据的逻辑单元，由一个或多个扇区组成

![image-20211202104839869](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20211202104839869.png)

### 在磁盘读写需要哪几部分时间？

- 寻道时间、旋转延迟时间、传输时间

![image-20220905215122727](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905215122727.png)



### 磁盘调度算法

#### 先来先服务（First Come First Served,FCFS）

FCFS算法根据进程请求访问磁盘的先后顺序进行调度

#### 最短寻找时间优先（Shortest Seek Time First,SSTF）

SSTF算法选择调度处理的磁道是与当前磁头所在磁道距离最近的，以便使每次寻找的时间最短，可能会有“饥饿”现象

#### 扫描算法（电梯调度算法）

SCAN算法在磁头当前移动方向上选择与当前磁头所在磁道距离最近的请求作为下一次服务的对象

![image-20220905215101946](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905215101946.png)

#### 循环扫描（Circular SCAN,C-SCAN）

在扫描算法的基础上**规定磁头单向移动**，扫到磁盘的一边之后，快速移动到起始端而不服务期间的任何请求

![image-20220905215321873](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905215321873.png)

![image-20220905215730846](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905215730846.png)

![image-20220905215740316](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220905215740316.png)
