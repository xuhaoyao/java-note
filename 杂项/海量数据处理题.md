# 海量数据处理题

## 一、海量日志数据，提取出某日访问网站次数最多的IP

假设内存无穷大、用常规的HashMap(ip，value)来统计ip出现的频率，同时用一个变量维护频率最多的那个ip即可

```java
List<String> target = new ArrayList<>();
int maxCnt = 0;
for(String ip : ipSets){
    int cnt = map.getOrDefault(ip,0);
    map.put(ip,++cnt);
    if(cnt > maxCnt){
        target.clear();
        maxCnt = cnt;
    }
    if(cnt == maxCnt){
        target.add(ip);
    }
}
```

内存放得下么？

- ip有 IPv4 和 IPv6，IPv4

- IPv4地址是类似 A.B.C.D 的格式，它是32位，用"."分成四段，用10进制表示

  IPv6地址类似
   XXXX:XXXX:XXXX:XXXX:XXXX:XXXX:XXXX:XXXX的格式，
   它是128位的，用":"分成8段，每个**X**是一个16进制数（16 = 2^4）

  

考虑实际情况，我们的内存是有限的，所以无法将海量日志数据一次性塞进内存里，那应该如何处理呢？很简单，分而治之！即将这些IP数据通过Hash映射算法划分为多个小文件，比如模1000，把整个大文件映射为1000个小文件，再找出每个小文件中出现频率最大的IP，最后在这1000个最大的IP中，找出那个频率最大的IP，即为所求（是不是很像Map Reduce的思想？）。

Hash取模是一种等价映射算法，不会存在同一个元素分散到不同小文件中的情况，这保证了我们分别在小文件统计IP出现频率的正确性。我们对IP进行模1000的时候，相同的IP在Hash取模后，只可能落在同一个小文件中，不可能被分散的。因为如果两个IP相等，那么经过Hash(IP)之后的哈希值是相同的，将此哈希值取模（如模1000），必定仍然相等。

总结一下，该类题型的解决方法分三步走：

- 分而治之、hash映射；
- HashMap（或前缀树）统计频率；
- 对于多个小文件，采用多路归并即可

改为出现次数前N的IP也是一样的做法

- 单个文件内，算法如下：
  - [347. 前 K 个高频元素 - 力扣（LeetCode）](https://leetcode.cn/problems/top-k-frequent-elements/)

- **单个文件求完后，多路归并，算法如下：**
  - 建立一个大小为N的小根堆
  - 每个文件按顺序依次弹出一个元素，直到文件弹空为止，放入小根堆
  - 若小根堆的数量小于N，那么直接放入
  - 若小根堆的数量等于N，比较堆顶，若当前元素的频率大于堆顶，那么堆顶弹出，放入这个元素



## 二、搜索引擎会通过日志文件把用户每次检索使用的所有查询串都记录下来，每个查询长度不超过 255 字节。假设目前有一千万个记录（这些查询串的重复度比较高，虽然总数是1千万，但如果除去重复后，不超过3百万个。一个查询串的重复度越高，说明查询它的用户越多，也就是越热门），请你统计最热门的10个查询串，要求使用的内存不能超过1G。

一千万个记录，除去重复后，实际上只有300万个不同的记录，每个记录假定为最大长度255Byte，则最多占用内存为：3M*1K/4=0.75G<1G，完全可以将所以查询记录存放在内存中进行处理。相较于第一道题目，这题还更简单了，直接HashMap（或前缀树）+堆排序即可。

具体做法如下：

遍历一遍左右的Query串，利用HashMap统计频率，时间复杂度为O(N)，N=1000万；

- 觉得慢的话可以用ConcurrentHashMap+多线程，并发去读日志文件，put进ConcurrentHashMap中

建立并维护一个大小为10的最小堆，然后遍历300万Query的频率，分别和根元素（最小值）进行对比，最后找到Top K，时间复杂度为N‘logK，N‘=300万，K=10。



## 三、**有一个1G大小的一个文件，里面每一行是一个词，词的大小不超过16字节，内存限制大小是1M。返回频数最高的100个词。**

分而治之 + hash统计 + 堆/快速排序。

具体做法如下：

分而治之、hash映射：遍历一遍文件，对于每个词x，取hash(x)并模5000，这样可以将文件里的所有词分别存到5000个小文件中，如果哈希函数设计得合理的话，每个文件大概是200k左右。就算其中有些文件超过了1M大小，还可以按照同样的方法继续往下分，直到分解得到的小文件的大小都不超过1M；
HashMap（或前缀树）统计频率：对于每个小文件，利用HashMap（或前缀树）统计词频；
堆排序：构建最小堆，堆的大小为100，找到频率最高的100个词。



## 四、给定a、b两个文件，各存放50亿个url，每个url各占64字节，内存限制是4G，让你找出a、b文件共同的url？

每个url是64字节，**50亿*64=5G×64=320G**，内存限制为4G，所以不能直接放入内存中。怎么办？分而治之！

具体做法如下：

1. 遍历文件a中的url，对url进行hash(url)%1000，将50亿的url分到1000个文件中存储（a0，a1，a2.......），**每个文件大约300多M**，对文件b进行同样的操作，**因为hash函数相同，所以相同的url必然会落到对应的文件中**，比如文件a中的url1与文件b中的url2相同，那么它们经过hash(url)%1000也是相同的。即**url1落入第n个文件中，url2也会落入到第n个文件中**。
2. 遍历a0中的url，存入HashSet中，同时遍历b0中的url，查看是否在HashSet中存在，如果存在则保存到单独的文件中。然后以此遍历剩余的小文件即可。



## 五、2.5亿个整数中找出不重复的整数的个数，内存空间不足以容纳这2.5亿个整数。

整数int有4个byte，所有整数个数有2^32，这里可以继续使用分而治之、hash映射的方法，即对于每个整数x，取hash(x)并模N，N代表划分的小文件个数，这样相同的整数会存入同一个文件，接着通过HashMap统计每个小文件中整数出现的频率（key为整数，value为频率），最后value为1的整数即为所求。

除此之外，我们还可以使用一种特殊的数据结构：位图（BitMap）。

位图的思想是用bit数组来记录0-1两种状态，可以将具体数据映射到这个bit数组的对应位置，bit数组中0表示数据存在，1表示数据不存在。举个例子，利用位图表示0-5中的元素，0-5中只有6个数，所以用6bit足以表示，例如3可以表示为[0,0,0,1,0,0]。位图在大量数据查询、去重等应用场景中使用的比较多，这个算法具有比较高的空间利用率。
回到该题，要找出不重复的整数，那么一个整数可以有三种状态，即不存在、存在1次、存在多次，根据题目需要找出的是存在1次的整数。对于三种状态只用0或1肯定是表示不了的，采用2-Bitmap（每个数分配2bit，00表示不存在，01表示出现一次，10表示多次，11无意义）。具体做法为：首先遍历所有整数，查看对应位图中对应的位，如果是 00，则变为 01，如果是 01 则变为 10，如果是 10 则保持不变。最后遍历位图，找出01对应的整数，即为2.5亿整数中只出现一次的整数。

我们也可以采用两个BitMap，即第一个Bitmap存储的是整数是否出现，接着，在之后的遍历先判断第一个BitMap里面是否出现过，如果出现就设置第二个BitMap对应的位置也为1，最后遍历BitMap，仅仅在一个BitMap中出现过的元素，就是不重复的整数。



### 位图的压缩技巧

**long占8个字节，64个bit，那么采用1-Bitmap的话，一个long就可以表示64个数**

- long[] bitmap = new long[2]
  - bitmap[0] 可以表示0~63 对应是否存在
    - 假如bitmap[0] = 5, 即 bitmap[0] = `101（2）`,那么数字0和数字2是存在的
  - bitmap[1] 可以表示64-127 对应是否存在



# 六、已知某个文件内包含一些电话号码，每个号码为 8 位数字，统计不同号码的个数。

使用位图法最为简单，每个号码八位数，不考虑实际情况，8位最多99 999 999，一共有10^8种情况，也就是需要10^8位bit，大概12.5M内存即可。申请一个数组，遍历所有号码，将号码对应的bit置为1，最后统计bit位1的数量即为不同的号码数。



# 七、一个文件中有5亿个int整数找它们的中位数

### 1.内存足够

直接排序或者双堆法

- [剑指 Offer 41. 数据流中的中位数 - 力扣（LeetCode）](https://leetcode.cn/problems/shu-ju-liu-zhong-de-zhong-wei-shu-lcof/)

### 2.对文件排序

分治到每个文件能读取到内存中 ，每一个文件内排序，然后外排序，最后整体有序，然后直接找5亿/2的下标和下一个数的平均数

### 3.分治

分治法的思想是把一个大的问题逐渐转换为规模较小的问题来求解。

对于这道题，顺序读取这 5 亿个数字，对于读取到的数字 num，如果它对应的二进制中最高位为 1，则把这个数字写到 f1 中，否则写入 f0 中。通过这一步，可以把这 5 亿个数划分为两部分，而且 f0 中的数都大于 f1 中的数（最高位是符号位）。

划分之后，可以非常容易地知道中位数是在 f0 还是 f1 中。假设 f1 中有 1 亿个数，那么中位数一定在 f0 中

对于 f0 可以用**次高位的二进制继续将文件一分为二**，如此划分下去，直到划分后的文件可以被加载到内存中，把数据加载到内存中以后直接排序，找出中位数。

> **注意**，当数据总数为偶数，如果划分后两个文件中的数据有相同个数，那么中位数就是数据较小的文件中的最大值与数据较大的文件中的最小值的平均值。