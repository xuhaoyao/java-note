# HTTP协议的演变

>  HTTP协议**定义了浏览器（万维网客户进程）怎样向万维网服务器请求万维网文档**，以及服务器怎样把文档传给客户端。它是万维网上能够**可靠**交换文件（文本、声音、图像等）的基础。



## **HTTP 1.0 和 HTTP 1.1 的主要区别是什么?**

HTTP/1.0默认使用的是短连接，每请求一个文档就需要2RTT的开销，每次请求都需要三次握手四次挥手的开销。

> **Connection： close**
>
> 从浏览器请求一个万维网文档到收到整个文档所需的时间大约是2RTT。（一个RTT用于TCP连接，三报文握手的前两部分，另一个RTT用于请求和接收万维网文档），TCP建立连接的三报文握手的第三个报文段中的数据，就是请求报文

HTTP/1.1默认使用的是长连接，服务器在发送响应后仍然在一段时间内保持这条连接，使同一个客户和服务器可以继续在这条连接上传送后续的HTTP请求报文和响应报文。

> **Connection: keep-alive**

**HTTP/1.1 的持续连接有非流水线方式和流水线方式** 。

非流水线方式的特点，客户在收到前一个响应后才能发出下一个请求。因此在TCP连接已建立后，每访问一个服务器都需要用去一个往返时间RTT。

流水线方式的特点，客户在收到HTTP的响应报文之前就能够接着发送新的报文请求，于是一个接一个的请求报文到达服务器后，服务器就可连续发回响应报文，因此使用流水线，客户访问所有对象只需要一个RTT时间。



> 说说 HTTP/1.1 相⽐ HTTP/1.0 提⾼了什么性能？

**HTTP/1.1 相⽐ HTTP/1.0 性能上的改进：**

- 使⽤ TCP ⻓连接的⽅式改善了 HTTP/1.0 短连接造成的性能开销。

- ⽀持管道（pipeline）⽹络传输，只要第⼀个请求发出去了，不必等其回来，就可以发第⼆个请求出去，可以

- 减少整体的响应时间。

**但 HTTP/1.1 还是有性能瓶颈：**

- 请求 / 响应头部（Header）未经压缩就发送，⾸部信息越多延迟越⼤。只能压缩 Body 的部分；

- 发送冗⻓的⾸部。每次互相发送相同的⾸部造成的浪费较多；

- 服务器是按请求的顺序响应的，如果服务器响应慢，会招致客户端⼀直请求不到数据，也就是**队头阻塞**；

- 没有请求优先级控制；

- 请求只能从客户端开始，服务器只能被动响应。



**那上⾯的 HTTP/1.1 的性能瓶颈，HTTP/2 做了什么优化？**



## HTTP2

![image-20220828150724841](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828150724841.png)

**HTTP/2** **协议是基于 HTTPS 的，所以 HTTP/2 的安全性也是有保障的。**

HTTP/2 相⽐ HTTP/1.1 性能上的改进：

### **1. 头部压缩**

HTTP/2 会压缩头（Header）如果你同时发出多个请求，他们的头是⼀样的或是相似的，那么，协议会帮你消除重复的部分。

这就是所谓的 `HPACK` 算法：在客户端和服务器同时维护⼀张**头信息表**，所有字段都会存⼊这个表，⽣成⼀个索引号，以后就不发送同样字段了，只发送索引号，这样就提⾼速度了。

#### 静态表编码

HTTP/2 为高频出现在头部的字符串和字段建立了一张静态表，它是写入到 HTTP/2 框架里的，不会变化的，静态 表里共有 61 组，如下图: 

![image-20220828150808190](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828150808190.png)

表中的 Index 表示索引(Key)， Header Value 表示索引对应的 Value， Header Name 表示字段的名字，比 如 Index 为 2 代表 GET，Index 为 8 代表状态码 200。 

你可能注意到，表中有的 Index 没有对应的 Header Value，这是因为这些 Value 并不是固定的而是变化的，这些 Value 都会经过 Huffman 编码后，才会发送出去。



#### 动态表编码

静态表只包含了 61 种高频出现在头部的字符串，不在静态表范围内的头部字符串就要自行构建动态表，它的 Index 从 62 起步，会在编码解码的时候随时更新。 

比如，第一次发送时头部中的「 user-agent 」字段数据有上百个字节，经过 Huffman 编码发送出去后，客户端 和服务器双方都会更新自己的动态表，添加一个新的 Index 号 62。那么在下一次发送的时候，就不用重复发这个 字段的数据了，只用发 **1** 个字节的 **Index** 号就好了，因为双方都可以根据自己的动态表获取到字段的数据。 

所以，使得**动态表生效有一个前提:必须同一个连接上，重复传输完全相同的 HTTP 头部。如果消息字段在 1 个连 接上只发送了 1 次，或者重复传输时，字段总是略有变化，动态表就无法被充分利用了。** 

因此，随着在**同一** **HTTP/2** **连接上**发送的报文越来越多，客户端和服务器双方的「字典」积累的越来越多，理论上 最终每个头部字段都会变成 1 个字节的 Index，这样便避免了大量的冗余数据的传输，大大节约了带宽。 

​                                                                             

理想很美好，现实很⻣感。动态表越大，占用的内存也就越大，如果占用了太多内存，是会影响服务器性能的，因 此 Web 服务器都会提供类似 http2_max_requests 的配置，用于限制一个连接上能够传输的请求数，避免动态 表无限增大，请求数到达上限后，就会关闭 HTTP/2 连接来释放内存。 

综上，**HTTP/2** **头部的编码通过「静态表、动态表、Huffman 编码」**共同完成的。 



### **2. ⼆进制格式**

HTTP/2 不再像 HTTP/1.1 ⾥的纯⽂本形式的报⽂，⽽是全⾯采⽤了**⼆进制格式**，头信息和数据体都是⼆进制，并且统称为帧（frame）：头信息帧和数据帧。

- **HTTP2最大的变化就是基于二进制流的传输**

![image-20220828150938944](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828150938944.png)

这样虽然对⼈不友好，但是对计算机⾮常友好，因为计算机只懂⼆进制，那么收到报⽂后，⽆需再将明⽂的报⽂转成⼆进制，⽽是直接解析⼆进制报⽂，**这增加了数据传输的效率**。

### **3. 数据流**

HTTP/2 的数据包不是按顺序发送的，同⼀个连接⾥⾯连续的数据包，可能属于不同的回应。因此，必须要对数据包做标记，指出它属于哪个回应。

每个请求或回应的所有数据包，称为⼀个数据流（ Stream ）。每个数据流都标记着⼀个独⼀⽆⼆的编号，**其中规定客户端发出的数据流编号为奇数， 服务器发出的数据流编号为偶数**

客户端还可以**指定数据流的优先级**。优先级⾼的请求，服务器就先响应该请求。

### **4. 多路复⽤**

HTTP/2 是可以在**⼀个连接中并发多个请求或回应，⽽不⽤按照顺序⼀⼀对应。**

移除了 HTTP/1.1 中的串⾏请求，不需要排队等待，也就不会再出现「队头阻塞」问题，降低了延迟，⼤幅度提⾼了连接的利⽤率。

举例来说，在⼀个 TCP 连接⾥，服务器收到了客户端 A 和 B 的两个请求，如果发现 A 处理过程⾮常耗时，于是就回应 A 请求已经处理好的部分，接着回应 B 请求，完成后，再回应 A 请求剩下的部分。

![image-20220828151128458](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828151128458.png)

![image-20220828151145443](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828151145443.png)

- 1 个 TCP 连接包含一个或者多个 Stream，Stream 是 HTTP/2 并发的关键技术;                   

- Stream 里可以包含 1 个或多个 Message，Message 对应 HTTP/1 中的请求或响应，由 HTTP 头部和包体构成; 

- Message 里包含一条或者多个 Frame，Frame 是 HTTP/2 最小单位，以二进制压缩格式存放 HTTP/1 中的内容(头部和包体); 

在 HTTP/2 连接上，不同 **Stream** 的帧是可以乱序发送的(因此可以并发不同的 **Stream** )，因为每个帧的头部会 携带 Stream ID 信息，所以接收端可以通过 Stream ID 有序组装成 HTTP 消息，而同一 **Stream** 内部的帧必须是严格有序的。 

   **HTTP 消息可以由多个 Frame 构成，以及 1 个 Frame 可以由多个TCP报文构成。**        

> HTTP/2 通信都在⼀个tcp连接上完成，这个连接会同时处理多个http的request，http2给每个http的request都分配唯一的streamId，而每个request切割出来的fram都共用这个streamId，这样的话http2就可以基于这个streamid将切割的信息还原

![image-20220828151422998](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828151422998.png)

### **5. 服务器推送**

HTTP/2 还在⼀定程度上改善了传统的「请求 - 应答」⼯作模式，服务不再是被动地响应，也可以主动向客户端发送消息。

举例来说，在浏览器刚请求 HTML 的时候，就提前把可能会⽤到的 JS、CSS ⽂件等静态资源主动发给客户端，减少延时的等待，也就是服务器推送（Server Push，也叫 Cache Push）。

> 客户端发起的请求，必须使用的是奇数号 Stream，服务器主动的推送，使用的是偶数号 Stream。服务器在推送资 源时，会通过 **PUSH_PROMISE** 帧传输 HTTP 头部，并通过帧中的 Promised Stream ID 字段告知客户端，接下来会在哪个偶数号 Stream 中发送包体。 



## 美中不足的HTTP2

HTTP/2 通过头部压缩、二进制编码、多路复用、服务器推送等新特性大幅度提升了 HTTP/1.1 的性能，而美中不 足的是 HTTP/2 协议是基于 TCP 实现的，于是存在的缺陷有下面几个。

- 升级 TCP 的工作很困难;

- 队头阻塞

- TCP 与 TLS 的握手时延迟; 

- 网络迁移时需要重新连接



### 升级TCP的工作很困难

TCP 协议是诞生在 1973 年，至今 TCP 协议依然还在实现很多的新特性。

但是 TCP 协议是在内核中实现的，应用程序只能使用不能修改，如果要想升级 TCP 协议，那么只能升级内核。

而升级内核这个工作是很麻烦的事情，麻烦的事情不是说升级内核这个操作很麻烦，而是由于内核升级涉及到底层软件和运行库的更新，我们的服务程序就需要回归测试是否兼容新的内核版本，所以服务器的内核升级比较保守和缓慢。

很多 TCP 协议的新特性，都是需要客户端和服务端同时支持才能生效的，比如 **TCP Fast Open** 这个特性，虽然在 2013 年就被提出了，但是由于因为很多 PC 端的系统升级滞后很严重，所以一些老旧的系统是无法支持这个特性的。



### 队头阻塞

HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输，这意味着多个 Stream 共用同一个 TCP 滑动窗口，那么当发生数据丢失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。

TCP 队头阻塞的问题要从两个角度看，一个是**发送窗口的队头阻塞**，另外一个是**接收窗口的队头阻塞**。

#### *1、发送窗口的队头阻塞。*

TCP 发送出去的数据，都是需要按序确认的，只有在数据都被按顺序确认完后，发送窗口才会往前滑动。

举个例子，比如下图的发送方把发送窗口内的数据全部都发出去了，可用窗口的大小就为 0 了，表明可用窗口耗尽，在没收到 ACK 确认之前是无法继续发送数据了。

![image-20220828152339327](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828152339327.png)

可用窗口耗尽

接着，当发送方收到对第 `32~36` 字节的 ACK 确认应答后，则**滑动窗口往右边移动 5 个字节，因为有 5 个字节的数据被应答确认**，接下来第 `52~56` 字节又变成了可用窗口，那么后续也就可以发送 `52~56` 这 5 个字节的数据了。

![image-20220828152411803](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828152411803.png)

32 ~ 36 字节已确认

**但是如果某个数据报文丢失或者其对应的 ACK 报文在网络中丢失，会导致发送方无法移动发送窗口，这时就无法再发送新的数据**，只能超时重传这个数据报文，直到收到这个重传报文的 ACK，发送窗口才会移动，继续后面的发送行为。

举个例子，比如下图，客户端是发送方，服务器是接收方。

![image-20220828152524590](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828152524590.png)

客户端发送了第 5～9 字节的数据，但是第 5 字节的 ACK 确认报文在网络中丢失了，那么即使客户端收到第 6～9 字节的 ACK 确认报文，发送窗口也不会往前移动。

**此时的第 5 字节相当于“队头”，因为没有收到“队头”的 ACK 确认报文，导致发送窗口无法往前移动，此时发送方就无法继续发送后面的数据，相当于按下了发送行为的暂停键，这就是发送窗口的队头阻塞问题**。

#### *2、接收窗口的队头阻塞。*

接收方收到的数据范围必须在接收窗口范围内，如果收到超过接收窗口范围的数据，就会丢弃该数据，比如下图接收窗口的范围是 32 ～ 51 字节，如果收到第 52 字节以上数据都会被丢弃。

![image-20220828152700835](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828152700835.png)

接收窗口

接收窗口什么时候才能滑动？当接收窗口收到有序数据时，接收窗口才能往前滑动，然后那些已经接收并且被确认的「有序」数据就可以被应用层读取。

但是，**当接收窗口收到的数据不是有序的，比如收到第 33～40 字节的数据，由于第 32 字节数据没有收到， 接收窗口无法向前滑动，那么即使先收到第 33～40 字节的数据，这些数据也无法被应用层读取的**。只有当发送方重传了第 32 字节数据并且被接收方收到后，接收窗口才会往前滑动，然后应用层才能从内核读取第 32～40 字节的数据。

好了，至此发送窗口和接收窗口的队头阻塞问题都说完了，这两个问题的原因都是因为 **TCP 必须按序处理数据，也就是 TCP 层为了保证数据的有序性，只有在处理完有序的数据后，滑动窗口才能往前滑动，否则就停留。**

- 停留「发送窗口」会使得发送方无法继续发送数据。
- 停留「接收窗口」会使得应用层无法读取新的数据。

其实也不能怪 TCP 协议，它本来设计目的就是为了保证数据的有序性。

**HTTP/2 多个 Stream 请求都是在一条 TCP 连接上传输，这意味着多个 Stream 共用同一个 TCP 滑动窗口，那么当发生数据丢失，滑动窗口是无法往前移动的，此时就会阻塞住所有的 HTTP 请求，这属于 TCP 层队头阻塞。**

![image-20220828152903740](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828152903740.png)



### 网络迁移需要重新连接 

一个 TCP 连接是由四元组(源 IP 地址，源端口，目标 IP 地址，目标端口)确定的，这意味着如果 IP 地址或者端 口变动了，就会导致需要 TCP 与 TLS 重新握手，这不利于移动设备切换网络的场景，比如 4G 网络环境切换成 WIFI。 



>  这些问题都是 TCP 协议固有的问题，无论应用层的 HTTP/2 在怎么设计都无法逃脱。要解决这个问题，HTTP3把传输层的TCP改成了UDP，解决了上述问题

![image-20220828153007691](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153007691.png)



## HTTP3

HTTP/3 不仅仅只是简单将传输协议替换成了 UDP，还基于 UDP 协议在「应用层」实现了 **QUIC** 协议，它 具有类似 TCP 的连接管理、拥塞窗口、流量控制的网络特性，相当于将不可靠传输的 UDP 协议变成“可靠”的了， 所以不用担心数据包丢失的问题。 

> Quick UDP Internet Connections

### QUIC 是如何实现可靠传输的?

要基于 UDP 实现的可靠传输协议，那么就要在应用层下功夫，也就是要设计好协议的头部字段。

拿 HTTP/3 举例子，在 UDP 报文头部与 HTTP 消息之间，共有 3 层头部：

![image-20220828153128340](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153128340.png)

![image-20220828153149286](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153149286.png)



#### Packet Header

Packet Header 首次建立连接时和日常传输数据时使用的 Header 是不同的。下图只画出了重要的字段：

![image-20220828153211944](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153211944.png)

细分这两种：

- Long Packet Header 用于首次建立连接。

- Short Packet Header 用于日常传输数据。

QUIC 也是需要三次握手来建立连接的，主要目的是为了确定连接 ID。

建立连接时，连接 ID 是由服务器根据客户端的 Source Connection ID 字段生成的，这样后续传输时，双方只需要固定住 Destination Connection ID(连接 ID )，从而实现连接迁移功能。所以，你可以看到日常传输数据的 Short Packet Header 不需要在传输 Source Connection ID 字段了。

Short Packet Header 中的 Packet Number 是每个报文独一无二的编号，它是严格递增的，也就是说就算 Packet N 丢失了，重传的 Packet N 的 Packet Number 已经不是 N，而是一个比 N 大的值。

![image-20220828153248454](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153248454.png)

Packet Number 单调递增的两个好处：

- 可以更加精确计算 RTT，没有 TCP 重传的歧义性问题;

- 可以支持乱序确认，防止因为丢包重传将当前窗口阻塞在原地，待发送端超过一定时间没收到 Packet N 的确认报文后，会将需要重传的数据包放到待发送队列，重新编号比如数据包 Packet N+M 后重新发送给接收端，对重传数据包的处理跟发送新的数据包类似，这样就不会因为丢包重传将当前窗口阻塞在原地，从而解决了队头阻塞问题。而 TCP 必须是顺序确认的，丢包时会导致窗口滑动;

#### QUIC Frame Header

一个 Packet 报文中可以存放多个 QUIC Frame。

![image-20220828153338431](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153338431.png)

每一个 Frame 都有明确的类型，针对类型的不同，功能也不同，自然格式也不同。我这里只举例 Stream 类型的 Frame 格式，Stream 可以认为就是一条 HTTP 请求，它长这样：

![image-20220828153357353](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153357353.png)

- Stream ID 作用：多个并发传输的 HTTP 消息，通过不同的 Stream ID 加以区别;

- Offset 作用：类似于 TCP 协议中的 Seq 序号，保证数据的顺序性和可靠性;

- Length 作用：指明了 Frame 数据的长度。

在前面介绍 Packet Header 时，说到 Packet Number 是严格递增，即使重传报文的 Packet Number 也是递增的，既然重传数据包的 Packet N+M 与丢失数据包的 Packet N 编号并不一致，我们怎么确定这两个数据包的内容一样呢?

所以引入 Frame Header 这一层，通过 Stream ID + Offset 字段信息实现数据的有序性，通过比较两个数据包的 Stream ID 与 Stream Offset ，如果都是一致，就说明这两个数据包的内容一致。

举个例子，下图中，数据包 Packet N 丢失了，后面重传该数据包的编号为 Packet N+2，丢失的数据包和重传的数据包 Stream ID 与 Offset 都一致，说明这两个数据包的内容一致。这些数据包传输到接收端后，接收端能根据 Stream ID 与 Offset 字段信息将 Stream x 和 Stream x+y 按照顺序组织起来，然后交给应用程序处理。

![image-20220828153445622](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153445622.png)

总的来说，QUIC 通过单向递增的 Packet Number，配合 Stream ID 与 Offset 字段信息，可以支持乱序确认而不影响数据包的正确组装，摆脱了TCP 必须按顺序确认应答 ACK 的限制，解决了 TCP 因某个数据包重传而阻塞后续所有待发送数据包的问题。



### QUIC 是如何解决 TCP 队头阻塞问题的?

QUIC 也借鉴 HTTP/2 里的 Stream 的概念，在一条 QUIC 连接上可以并发发送多个 HTTP 请求 (Stream)。

但是 **QUIC 给每一个 Stream 都分配了一个独立的滑动窗口，这样使得一个连接上的多个 Stream 之间没有依赖关系，都是相互独立的，各自控制的滑动窗口。**

假如 Stream2 丢了一个 UDP 包，也只会影响 Stream2 的处理，不会影响其他 Stream，与 HTTP/2 不同，HTTP/2 只要某个流中的数据包丢失了，其他流也会因此受影响。

![image-20220828153530087](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153530087.png)



### QUIC 是如何做流量控制的?

TCP 流量控制是通过让「接收方」告诉「发送方」，它(接收方)的接收窗口有多大，从而让「发送方」根据「接收方」的实际接收能力控制发送的数据量。

TCP 的接收窗口在收到有序的数据后，接收窗口才能往前滑动，否则停止滑动;TCP 的发送窗口在收到对已发送数据的顺序确认 ACK后，发送窗口才能往前滑动，否则停止滑动。

QUIC 是基于 UDP 传输的，而 UDP 没有流量控制，因此 QUIC 实现了自己的流量控制机制。不过，QUIC 的滑动窗口滑动的条件跟 TCP 有所差别的。

QUIC 实现了两种级别的流量控制，分别为 Stream 和 Connection 两种级别：

- Stream 级别的流量控制：每个 Stream 都有独立的滑动窗口，所以每个 Stream 都可以做流量控制，防止单个 Stream 消耗连接(Connection)的全部接收缓冲。

- Connection 流量控制：限制连接中所有 Stream 相加起来的总字节数，防止发送方超过连接的缓冲容量。



#### Stream 级别的流量控制

回想一下 TCP，当发送方发送 seq1、seq2、seq3 报文，由于 seq2 报文丢失了，接收方收到 seq1 后会 ack1，然后接收方收到 seq3 后还是回 ack1(因为没有收到 seq2)，这时发送窗口无法往前滑动。

但是，QUIC 就不一样了，即使中途有报文丢失，发送窗口依然可以往前滑动，具体怎么做到的呢?我们来看看。

最开始，接收方的接收窗口初始状态如下：

![image-20220828153628959](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153628959.png)

接着，接收方收到了发送方发送过来的数据，有的数据被上层读取了，有的数据丢包了，此时的接收窗口状况如下：

![image-20220828153644061](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153644061.png)

可以看到，接收窗口的左边界取决于接收到的最大偏移字节数，此时的接收窗口 = 最大窗口数 - 接收到的最大偏移数，这里就跟 TCP 不一样了。

那接收窗口触发的滑动条件是什么呢?看下图：

![image-20220828153711999](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828153711999.png)

当图中的绿色部分数据超过最大接收窗口的一半后，最大接收窗口向右移动，同时给对端发送**「窗口更新帧」**。当发送方收到接收方的窗口更新帧后，发送窗口也会往前滑动，即使中途有丢包，依然也会滑动，这样就防止像 TCP 那样在出现丢包的时候，导致发送窗口无法移动，从而避免了无法继续发送数据。

在前面我们说过，每个 Stream 都有各自的滑动窗口，不同 Stream 互相独立，队头的 Stream A 被阻塞后，不妨碍 StreamB、C的读取。而对于 TCP 而言，其不知道将不同的 Stream 交给上层哪一个请求，因此同一个Connection内，Stream A 被阻塞后，StreamB、C 必须等待。

经过了解完 QUIC 的流量控制机制后，对于队头阻塞问题解决得更加彻底。

QUIC 协议中同一个 Stream 内，滑动窗口的移动仅取决于接收到的最大字节偏移(尽管期间可能有部分数据未被接收)，而对于 TCP 而言，窗口滑动必须保证此前的 packet 都有序的接收到了，其中一个 packet 丢失就会导致窗口等待。



#####  QUIC 支持乱序确认，具体是怎么做到的呢？

如图所示，当前发送方的缓冲区大小为8，发送方 QUIC 按序（offset顺序）发送 29-36 的数据包：

![image-20220828154159048](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828154159048.png)

31、32、34数据包先到达，基于 offset 被优先乱序确认，但 30 数据包没有确认，所以当前已提交的字节偏移量不变，发送方的缓存区不变。

![image-20220828154224560](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828154224560.png)

30 到达并确认，发送方的缓存区收缩到阈值，接收方发送 MAX_STREAM_DATA Frame（协商缓存大小的特定帧）给发送方，请求增长最大绝对字节偏移量。

![image-20220828154340453](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828154340453.png)

协商完毕后最大绝对字节偏移量右移，发送方的缓存区变大，同时发送方发现数据包33超时

![image-20220828154400525](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828154400525.png)

发送方将超时数据包重新编号为 42 继续发送

![image-20220828154417674](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828154417674.png)

以上就是最基本的数据包发送-接收过程，控制数据发送的唯一限制就是最大绝对字节偏移量，该值是接收方基于当前已经提交的偏移量（连续已确认并向上层应用提交的数据包offset）和发送方协商得出。



#### Connection 流量控制

而对于 Connection 级别的流量窗口，其接收窗口大小就是各个 Stream 接收窗口大小之和。

![image-20220828154456184](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828154456184.png)

上图所示的例子，所有 Streams 的最大窗口数为 120，其中：

- Stream 1 的最大接收偏移为 100，可用窗口 = 120 - 100 = 20
- Stream 2 的最大接收偏移为 90，可用窗口 = 120 - 90 = 30
- Stream 3 的最大接收偏移为 110，可用窗口 = 120 - 110 = 10

那么整个 Connection 的可用窗口 = 20 + 30 + 10 = 60

```undefined
可用窗口 = Stream 1 可用窗口 + Stream 2 可用窗口 + Stream 3 可用窗口
```



### QUIC 对拥塞控制改进

QUIC 协议当前默认使用了 TCP 的 Cubic 拥塞控制算法(我们熟知的慢开始、拥塞避免、快重传、快恢复策略)，同时也支持 CubicBytes、Reno、RenoBytes、BBR、PCC 等拥塞控制算法，相当于将 TCP 的拥塞控制算法照搬过来了，QUIC 是如何改进 TCP 的拥塞控制算法的呢?

QUIC 是处于应用层的，应用程序层面就能实现不同的拥塞控制算法，不需要操作系统，不需要内核支持。这是一个飞跃，因为传统的 TCP 拥塞控制，必须要端到端的网络协议栈支持，才能实现控制效果。而内核和操作系统的部署成本非常高，升级周期很长，所以 TCP 拥塞控制算法迭代速度是很慢的。而 QUIC 可以随浏览器更新，QUIC 的拥塞控制算法就可以有较快的迭代速度。

TCP 更改拥塞控制算法是对系统中所有应用都生效，无法根据不同应用设定不同的拥塞控制策略。但是因为 **QUIC** **处于应用层，所以就可以针对不同的应用设置不同的拥塞控制算法，这样灵活性就很高了**。



### QUIC 是如何迁移连接的?

基于 TCP 传输协议的 HTTP 协议，由于是通过四元组(源 IP、源端口、目的 IP、目的端口)确定一条 TCP 连接。

那么当移动设备的网络从 4G 切换到 WIFI 时，意味着 IP 地址变化了，那么就必须要断开连接，然后重新建立 TCP 连接。

而**建立连接的过程包含** **TCP** **三次握手和** **TLS** **四次握手的时延，以及 TCP 慢启动的减速过程，给用户的感觉就是网络突然卡顿了一下，因此连接的迁移成本是很高的。**

QUIC 协议没有用四元组的方式来“绑定”连接，而是通过连接 ID来标记通信的两个端点，客户端和服务器可以各自选择一组 ID 来标记自己，因此即使移动设备的网络变化后，导致 IP 地址变化了，只要仍保有上下文信息(比如连接 ID、TLS 密钥等)，就可以“无缝”地复用原连接，消除重连的成本，没有丝毫卡顿感，达到了连接迁移的功能。

> 这个 ID 是客户端随机产生的，并且长度有 64 位



## 补充

### TCP Fast Open

TCP 三次握手的延迟被 TCP Fast Open (快速打开)这个特性解决了，这个特性可以在「第二次建立连接」时减少 TCP 连接建立的时延。

![image-20220828154950629](https://raw.githubusercontent.com/xuhaoyao/images/master/img/image-20220828154950629.png)

Fast Open HTTP 请求过程如下：

- 在第一次建立连接的时候，服务端在第二次握手产生一个 Cookie (已加密)并通过 SYN、ACK 包一起发给客户端，于是客户端就会缓存这个 Cookie，所以第一次发起 HTTP Get 请求的时候，还是需要 2 个 RTT 的时延;

- 在下次请求的时候，客户端在 SYN 包带上 Cookie 发给服务端，就提前可以跳过三次握手的过程，因为 Cookie 中维护了一些信息，服务端可以从 Cookie 获取 TCP 相关的信息，这时发起的 HTTP GET 请求就只需要 1 个 RTT 的时延;

TCP Fast Open 这个特性是不错，但是它需要服务端和客户端的操作系统同时支持才能体验到，而 TCP Fast Open 是在 2013 年提出的，所以市面上依然有很多老式的操作系统不支持，而升级操作系统是很麻烦的事情，因此 TCP Fast Open 很难被普及开来。